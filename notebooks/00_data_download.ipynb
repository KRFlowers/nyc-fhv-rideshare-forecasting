{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYC Rideshare Data Download Notebook\n",
    "\n",
    "This notebook downloads 36 months of NYC Taxi & Limousine Commission (TLC) High Volume FHV (Uber/Lyft) trip records. Data is for the years 2022-2024. This data will be validated, analyzed for demand patterns, and used to build zone-level forecasting models. \n",
    "\n",
    "**Pipeline Position:** Notebook 1 of 4: Data Download\n",
    "\n",
    "- 00_data_download.ipynb ← **this notebook**\n",
    "- 01_data_validation.ipynb\n",
    "- 02_exploratory_analysis.ipynb\n",
    "- 03_demand_forecasting.ipynb\n",
    "\n",
    "**Objective:** The notebook acquires and consolidates the initial dataset that will be used for validation, exploration, and modeling stages.\n",
    "\n",
    "**Technical Approach:**\n",
    "- Build list of monthly file URLs for 2022–2024\n",
    "- Download each Parquet file (skip existing)\n",
    "- Consolidate files using DuckDB\n",
    "- Download zone metadata for later analysis\n",
    "\n",
    "**Inputs:**\n",
    "- 2022–2024 NYC TLC FHVHV trip data (publicly available from NYC Open Data)\n",
    "\n",
    "**Outputs:**\n",
    "- `data\\raw\\combined_fhvhv_tripdata.parquet`  (~18GB total)\n",
    "- `data\\raw\\zone_metadata.csv` — Zone reference data\n",
    "\n",
    "**Runtime:** ~1 hour first run; skips existing files on rerun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Set Up Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from pathlib import Path\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2 Configure Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Config loaded: FHVHV 2022-2024\n"
     ]
    }
   ],
   "source": [
    "# Project Constants\n",
    "PROJECT_YEARS = [2022, 2023, 2024]\n",
    "TLC_DATASET = 'fhvhv'\n",
    "\n",
    "# Paths\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "RAW_DIR = PROJECT_ROOT / \"data\" / \"raw\"  # Source files + combined dataset\n",
    "\n",
    "# Notebook Configuration\n",
    "BASE_URL = \"https://d37ci6vzurychx.cloudfront.net/trip-data\"\n",
    "OUTPUT_FILE = RAW_DIR / f\"combined_{TLC_DATASET}_tripdata.parquet\"\n",
    "\n",
    "# Create Directory\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"✓ Config loaded: {TLC_DATASET.upper()} {PROJECT_YEARS[0]}-{PROJECT_YEARS[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Download Data\n",
    "Creates file list, downloads monthly trip files, and retrieves zone metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1 Build Download List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Generated list of 36 files to download\n"
     ]
    }
   ],
   "source": [
    "files_to_download = [\n",
    "    f\"{TLC_DATASET}_tripdata_{year}-{month:02d}.parquet\"\n",
    "    for year in PROJECT_YEARS\n",
    "    for month in range(1, 13)\n",
    "]\n",
    "\n",
    "print(f\"✓ Generated list of {len(files_to_download)} files to download\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2 Download Trip Files (~10-20 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/36] fhvhv_tripdata_2022-01.parquet... \n",
      "[2/36] fhvhv_tripdata_2022-02.parquet... \n",
      "[3/36] fhvhv_tripdata_2022-03.parquet... \n",
      "[4/36] fhvhv_tripdata_2022-04.parquet... \n",
      "[5/36] fhvhv_tripdata_2022-05.parquet... \n",
      "[6/36] fhvhv_tripdata_2022-06.parquet... \n",
      "[7/36] fhvhv_tripdata_2022-07.parquet... \n",
      "[8/36] fhvhv_tripdata_2022-08.parquet... \n",
      "[9/36] fhvhv_tripdata_2022-09.parquet... \n",
      "[10/36] fhvhv_tripdata_2022-10.parquet... \n",
      "[11/36] fhvhv_tripdata_2022-11.parquet... \n",
      "[12/36] fhvhv_tripdata_2022-12.parquet... \n",
      "[13/36] fhvhv_tripdata_2023-01.parquet... \n",
      "[14/36] fhvhv_tripdata_2023-02.parquet... \n",
      "[15/36] fhvhv_tripdata_2023-03.parquet... \n",
      "[16/36] fhvhv_tripdata_2023-04.parquet... \n",
      "[17/36] fhvhv_tripdata_2023-05.parquet... \n",
      "[18/36] fhvhv_tripdata_2023-06.parquet... \n",
      "[19/36] fhvhv_tripdata_2023-07.parquet... \n",
      "[20/36] fhvhv_tripdata_2023-08.parquet... \n",
      "[21/36] fhvhv_tripdata_2023-09.parquet... \n",
      "[22/36] fhvhv_tripdata_2023-10.parquet... \n",
      "[23/36] fhvhv_tripdata_2023-11.parquet... \n",
      "[24/36] fhvhv_tripdata_2023-12.parquet... \n",
      "[25/36] fhvhv_tripdata_2024-01.parquet... \n",
      "[26/36] fhvhv_tripdata_2024-02.parquet... \n",
      "[27/36] fhvhv_tripdata_2024-03.parquet... \n",
      "[28/36] fhvhv_tripdata_2024-04.parquet... \n",
      "[29/36] fhvhv_tripdata_2024-05.parquet... \n",
      "[30/36] fhvhv_tripdata_2024-06.parquet... \n",
      "[31/36] fhvhv_tripdata_2024-07.parquet... \n",
      "[32/36] fhvhv_tripdata_2024-08.parquet... \n",
      "[33/36] fhvhv_tripdata_2024-09.parquet... \n",
      "[34/36] fhvhv_tripdata_2024-10.parquet... \n",
      "[35/36] fhvhv_tripdata_2024-11.parquet... \n",
      "[36/36] fhvhv_tripdata_2024-12.parquet... \n",
      "\n",
      "Download complete: 36 files available\n"
     ]
    }
   ],
   "source": [
    "downloaded_files = []\n",
    "failed_files = []\n",
    "\n",
    "for i, filename in enumerate(files_to_download, 1):\n",
    "    url = f\"{BASE_URL}/{filename}\"\n",
    "    save_path = RAW_DIR / filename\n",
    "    \n",
    "    # Skip files that already exist\n",
    "    if save_path.exists():\n",
    "        downloaded_files.append(save_path)\n",
    "        continue\n",
    "    \n",
    "    # Download with error handling\n",
    "    try:\n",
    "        print(f\"[{i}/{len(files_to_download)}] {filename}...\", end=\" \")\n",
    "        urllib.request.urlretrieve(url, save_path)\n",
    "        downloaded_files.append(save_path)\n",
    "        print(\"\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ {str(e)[:50]}\")\n",
    "        failed_files.append(filename)\n",
    "\n",
    "# Summary\n",
    "print(f\"\\nDownload complete: {len(downloaded_files)} files available\")\n",
    "if failed_files:\n",
    "    print(f\"Failed: {len(failed_files)} files (may not exist yet)\")\n",
    "    for fname in failed_files[:5]:\n",
    "        print(f\"  - {fname}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3 Download Zone MetaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zone metadata saved: C:\\Users\\kristi\\OneDrive\\GitHub Repositories\\DataScienceProjects\\nyc-fhv-rideshare-forecasting\\data\\raw\\zone_metadata.csv\n",
      "Total zones: 265\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zone_id</th>\n",
       "      <th>Borough</th>\n",
       "      <th>Zone</th>\n",
       "      <th>service_zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>EWR</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>EWR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Queens</td>\n",
       "      <td>Jamaica Bay</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>Allerton/Pelham Gardens</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Alphabet City</td>\n",
       "      <td>Yellow Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>Arden Heights</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   zone_id        Borough                     Zone service_zone\n",
       "0        1            EWR           Newark Airport          EWR\n",
       "1        2         Queens              Jamaica Bay    Boro Zone\n",
       "2        3          Bronx  Allerton/Pelham Gardens    Boro Zone\n",
       "3        4      Manhattan            Alphabet City  Yellow Zone\n",
       "4        5  Staten Island            Arden Heights    Boro Zone"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NYC TLC zone metadata for zone names and boroughs \n",
    "\n",
    "zone_metadata_url = \"https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv\"\n",
    "zone_metadata_file = RAW_DIR / \"zone_metadata.csv\"\n",
    "\n",
    "if not zone_metadata_file.exists():\n",
    "    urllib.request.urlretrieve(zone_metadata_url, zone_metadata_file)\n",
    "    \n",
    "    # Rename LocationID column to zone_id for consistency\n",
    "    zone_metadata = pd.read_csv(zone_metadata_file)\n",
    "    zone_metadata = zone_metadata.rename(columns={'LocationID': 'zone_id'})\n",
    "    zone_metadata.to_csv(zone_metadata_file, index=False)\n",
    "    print(f\"Zone metadata saved: {zone_metadata_file}\")\n",
    "else:\n",
    "    zone_metadata = pd.read_csv(zone_metadata_file)\n",
    "    print(f\"Zone metadata exists, skipping download\")\n",
    "\n",
    "print(f\"Total zones: {len(zone_metadata)}\")\n",
    "zone_metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Combine Files (~5-10 minutes)\n",
    "Combines all monthly files into a single dataset using DuckDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ DuckDB connection established\n"
     ]
    }
   ],
   "source": [
    "# Initialize DuckDB connection with memory-efficient settings\n",
    "con = duckdb.connect()\n",
    "con.execute(\"SET threads=4\")\n",
    "con.execute(\"SET preserve_insertion_order=false\")\n",
    "#con.execute(\"SET enable_progress_bar = true\")\n",
    "#con.execute(\"SET progress_bar_time = 2000\")\n",
    "print(\"✓ DuckDB connection established\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining 36 files and saving to: combined_fhvhv_tripdata.parquet...\n",
      "Saved: 18830.1 MB (18.39 GB)\n"
     ]
    }
   ],
   "source": [
    "# Combine files and export using downloaded file list\n",
    "file_list_sql = \", \".join([f\"'{str(f)}'\" for f in downloaded_files])\n",
    "\n",
    "print(f\"Combining {len(downloaded_files)} files and saving to: {OUTPUT_FILE.name}...\")\n",
    "con.execute(f\"\"\"\n",
    "    COPY (\n",
    "        SELECT * FROM read_parquet([{file_list_sql}])\n",
    "    )\n",
    "    TO '{str(OUTPUT_FILE)}'\n",
    "    (FORMAT PARQUET, COMPRESSION SNAPPY)\n",
    "\"\"\")\n",
    "\n",
    "parquet_file_size_mb = OUTPUT_FILE.stat().st_size / 1024**2\n",
    "print(f\"Saved: {parquet_file_size_mb:.1f} MB ({parquet_file_size_mb/1024:.2f} GB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Verify Data\n",
    "Checks record counts, date range, columns, and sample records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1 Review Dataset Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Dataset summary complete: 684,376,551 records\n"
     ]
    }
   ],
   "source": [
    "# Query combined file counts and date range\n",
    "summary = con.execute(f\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as row_count,\n",
    "        MIN(pickup_datetime) as start_date,\n",
    "        MAX(pickup_datetime) as end_date\n",
    "    FROM '{OUTPUT_FILE}'\n",
    "\"\"\").fetchone()\n",
    "\n",
    "row_count, start_date, end_date = summary\n",
    "\n",
    "# Display column information\n",
    "columns = con.execute(f\"DESCRIBE SELECT * FROM '{OUTPUT_FILE}'\").df()\n",
    "column_names = columns['column_name'].tolist()\n",
    "\n",
    "# Verify expected columns (ensures schema has not changed and validates data integrity)\n",
    "expected_columns = ['hvfhs_license_num', 'pickup_datetime', 'dropoff_datetime', \n",
    "                   'trip_miles', 'base_passenger_fare']\n",
    "missing_cols = [col for col in expected_columns if col not in column_names]\n",
    "print(f\"✓ Dataset summary complete: {row_count:,} records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATASET SUMMARY\n",
      "============================================================\n",
      "\n",
      "Rows:        684,376,551\n",
      "Columns:     24\n",
      "Date range:  2022-01-01 00:00:00 to 2024-12-31 23:59:59\n",
      "File size:   18830.1 MB (18.39 GB)\n",
      "\n",
      "Expected columns checked:\n",
      "  yes   hvfhs_license_num\n",
      "  yes   pickup_datetime\n",
      "  yes   dropoff_datetime\n",
      "  yes   trip_miles\n",
      "  yes   base_passenger_fare\n"
     ]
    }
   ],
   "source": [
    "# Print dataset summary results\n",
    "print(\"=\"*60)\n",
    "print(\"DATASET SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nRows:        {row_count:,}\")\n",
    "print(f\"Columns:     {len(column_names)}\")\n",
    "print(f\"Date range:  {start_date} to {end_date}\")\n",
    "print(f\"File size:   {parquet_file_size_mb:.1f} MB ({parquet_file_size_mb/1024:.2f} GB)\")\n",
    "\n",
    "# print results of expected columns check\n",
    "print(f\"\\nExpected columns checked:\")\n",
    "for col in expected_columns:\n",
    "    status = \"yes  \" if col in column_names else \"No MISSING\"\n",
    "    print(f\"  {status} {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Date range spans 2022-01-01 to 2024-12-31 as expected. Completeness by zone verified in EDA notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2 Review Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>column_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hvfhs_license_num</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dispatching_base_num</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>originating_base_num</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>request_datetime</td>\n",
       "      <td>TIMESTAMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>on_scene_datetime</td>\n",
       "      <td>TIMESTAMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pickup_datetime</td>\n",
       "      <td>TIMESTAMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dropoff_datetime</td>\n",
       "      <td>TIMESTAMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PULocationID</td>\n",
       "      <td>BIGINT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DOLocationID</td>\n",
       "      <td>BIGINT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>trip_miles</td>\n",
       "      <td>DOUBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>trip_time</td>\n",
       "      <td>BIGINT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>base_passenger_fare</td>\n",
       "      <td>DOUBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tolls</td>\n",
       "      <td>DOUBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bcf</td>\n",
       "      <td>DOUBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sales_tax</td>\n",
       "      <td>DOUBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>congestion_surcharge</td>\n",
       "      <td>DOUBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>airport_fee</td>\n",
       "      <td>DOUBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tips</td>\n",
       "      <td>DOUBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>driver_pay</td>\n",
       "      <td>DOUBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>shared_request_flag</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>shared_match_flag</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>access_a_ride_flag</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>wav_request_flag</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>wav_match_flag</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             column_name column_type\n",
       "0      hvfhs_license_num     VARCHAR\n",
       "1   dispatching_base_num     VARCHAR\n",
       "2   originating_base_num     VARCHAR\n",
       "3       request_datetime   TIMESTAMP\n",
       "4      on_scene_datetime   TIMESTAMP\n",
       "5        pickup_datetime   TIMESTAMP\n",
       "6       dropoff_datetime   TIMESTAMP\n",
       "7           PULocationID      BIGINT\n",
       "8           DOLocationID      BIGINT\n",
       "9             trip_miles      DOUBLE\n",
       "10             trip_time      BIGINT\n",
       "11   base_passenger_fare      DOUBLE\n",
       "12                 tolls      DOUBLE\n",
       "13                   bcf      DOUBLE\n",
       "14             sales_tax      DOUBLE\n",
       "15  congestion_surcharge      DOUBLE\n",
       "16           airport_fee      DOUBLE\n",
       "17                  tips      DOUBLE\n",
       "18            driver_pay      DOUBLE\n",
       "19   shared_request_flag     VARCHAR\n",
       "20     shared_match_flag     VARCHAR\n",
       "21    access_a_ride_flag     VARCHAR\n",
       "22      wav_request_flag     VARCHAR\n",
       "23        wav_match_flag     VARCHAR"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List columns with data types\n",
    "con.execute(f\"DESCRIBE SELECT * FROM '{OUTPUT_FILE}'\").df()[['column_name', 'column_type']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.3 Preview Sample Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hvfhs_license_num</th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>originating_base_num</th>\n",
       "      <th>request_datetime</th>\n",
       "      <th>on_scene_datetime</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>trip_time</th>\n",
       "      <th>base_passenger_fare</th>\n",
       "      <th>tolls</th>\n",
       "      <th>bcf</th>\n",
       "      <th>sales_tax</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>tips</th>\n",
       "      <th>driver_pay</th>\n",
       "      <th>shared_request_flag</th>\n",
       "      <th>shared_match_flag</th>\n",
       "      <th>access_a_ride_flag</th>\n",
       "      <th>wav_request_flag</th>\n",
       "      <th>wav_match_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2022-01-01 00:05:31</td>\n",
       "      <td>2022-01-01 00:05:40</td>\n",
       "      <td>2022-01-01 00:07:24</td>\n",
       "      <td>2022-01-01 00:18:28</td>\n",
       "      <td>170</td>\n",
       "      <td>161</td>\n",
       "      <td>1.18</td>\n",
       "      <td>664</td>\n",
       "      <td>24.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.21</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.03</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2022-01-01 00:19:27</td>\n",
       "      <td>2022-01-01 00:22:08</td>\n",
       "      <td>2022-01-01 00:22:32</td>\n",
       "      <td>2022-01-01 00:30:12</td>\n",
       "      <td>237</td>\n",
       "      <td>161</td>\n",
       "      <td>0.82</td>\n",
       "      <td>460</td>\n",
       "      <td>11.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.06</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.32</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2022-01-01 00:43:53</td>\n",
       "      <td>2022-01-01 00:57:37</td>\n",
       "      <td>2022-01-01 00:57:37</td>\n",
       "      <td>2022-01-01 01:07:32</td>\n",
       "      <td>237</td>\n",
       "      <td>161</td>\n",
       "      <td>1.18</td>\n",
       "      <td>595</td>\n",
       "      <td>29.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.30</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2022-01-01 00:15:36</td>\n",
       "      <td>2022-01-01 00:17:08</td>\n",
       "      <td>2022-01-01 00:18:02</td>\n",
       "      <td>2022-01-01 00:23:05</td>\n",
       "      <td>262</td>\n",
       "      <td>229</td>\n",
       "      <td>1.65</td>\n",
       "      <td>303</td>\n",
       "      <td>7.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.30</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2022-01-01 00:25:45</td>\n",
       "      <td>2022-01-01 00:26:01</td>\n",
       "      <td>2022-01-01 00:28:01</td>\n",
       "      <td>2022-01-01 00:35:42</td>\n",
       "      <td>229</td>\n",
       "      <td>141</td>\n",
       "      <td>1.65</td>\n",
       "      <td>461</td>\n",
       "      <td>9.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.84</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.44</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  hvfhs_license_num dispatching_base_num originating_base_num  \\\n",
       "0            HV0003               B03404               B03404   \n",
       "1            HV0003               B03404               B03404   \n",
       "2            HV0003               B03404               B03404   \n",
       "3            HV0003               B03404               B03404   \n",
       "4            HV0003               B03404               B03404   \n",
       "\n",
       "     request_datetime   on_scene_datetime     pickup_datetime  \\\n",
       "0 2022-01-01 00:05:31 2022-01-01 00:05:40 2022-01-01 00:07:24   \n",
       "1 2022-01-01 00:19:27 2022-01-01 00:22:08 2022-01-01 00:22:32   \n",
       "2 2022-01-01 00:43:53 2022-01-01 00:57:37 2022-01-01 00:57:37   \n",
       "3 2022-01-01 00:15:36 2022-01-01 00:17:08 2022-01-01 00:18:02   \n",
       "4 2022-01-01 00:25:45 2022-01-01 00:26:01 2022-01-01 00:28:01   \n",
       "\n",
       "     dropoff_datetime  PULocationID  DOLocationID  trip_miles  trip_time  \\\n",
       "0 2022-01-01 00:18:28           170           161        1.18        664   \n",
       "1 2022-01-01 00:30:12           237           161        0.82        460   \n",
       "2 2022-01-01 01:07:32           237           161        1.18        595   \n",
       "3 2022-01-01 00:23:05           262           229        1.65        303   \n",
       "4 2022-01-01 00:35:42           229           141        1.65        461   \n",
       "\n",
       "   base_passenger_fare  tolls   bcf  sales_tax  congestion_surcharge  \\\n",
       "0                24.90    0.0  0.75       2.21                  2.75   \n",
       "1                11.97    0.0  0.36       1.06                  2.75   \n",
       "2                29.82    0.0  0.89       2.65                  2.75   \n",
       "3                 7.91    0.0  0.24       0.70                  2.75   \n",
       "4                 9.44    0.0  0.28       0.84                  2.75   \n",
       "\n",
       "   airport_fee  tips  driver_pay shared_request_flag shared_match_flag  \\\n",
       "0          0.0   0.0       23.03                   N                 N   \n",
       "1          0.0   0.0       12.32                   N                 N   \n",
       "2          0.0   0.0       23.30                   N                 N   \n",
       "3          0.0   0.0        6.30                   N                 N   \n",
       "4          0.0   0.0        7.44                   N                 N   \n",
       "\n",
       "  access_a_ride_flag wav_request_flag wav_match_flag  \n",
       "0                                   N              N  \n",
       "1                                   N              N  \n",
       "2                                   N              N  \n",
       "3                                   N              N  \n",
       "4                                   N              N  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display sample records in transposed format\n",
    "sample_df = con.execute(f\"\"\"\n",
    "    SELECT * FROM '{OUTPUT_FILE}' LIMIT 4\n",
    "\"\"\").df()\n",
    "\n",
    "# Preview sample records  and set to scrollable\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "con.execute(f\"SELECT * FROM '{OUTPUT_FILE}' LIMIT 5\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Complete\n"
     ]
    }
   ],
   "source": [
    "# Close DuckDB connection and release resources and file locks\n",
    "con.close()\n",
    "print(\"\\n Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset Summary:**\n",
    "- 684 million records\n",
    "- 36 months of coverage\n",
    "- All expected columns present\n",
    "\n",
    "Data is ready for validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "This notebook downloaded and consolidated 36 months of NYC TLC FHVHV trip data into a single 18GB dataset with 684 million records.\n",
    "\n",
    "**Technical Decisions**\n",
    "\n",
    "- Pandas failed on 18GB dataset with out-of-memory errors—DuckDB solved this\n",
    "- DuckDB settings (`threads=4`, `preserve_insertion_order=false`) reduced combine time from 30+ minutes to 6 minutes by allowing parallel streaming writes\n",
    "- Glob patterns retrieve and combine files in one operation\n",
    "- Pipeline is reproducible on standard hardware (32GB desktop, ~2 hours total)\n",
    "\n",
    "**Output Files**\n",
    "\n",
    "- `data/raw/combined_fhvhv_tripdata.parquet` — Combined dataset (18.35 GB)\n",
    "- `data/raw/zone_metadata.csv` — Zone reference data\n",
    "\n",
    "**Next Steps**\n",
    "\n",
    "Proceed to **01_data_validation.ipynb** for quality checks on duration, distance, and fare fields."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
