{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYC Rideshare Forecasting Pipeline - Part 1: Data Download\n",
    "\n",
    "**Author:** K Flowers  \n",
    "**GitHub:** [github.com/KRFlowers](https://github.com/KRFlowers)  \n",
    "**Date:** December 2025\n",
    "\n",
    "This notebook downloads 36 months of NYC Taxi & Limousine Commission (TLC) High Volume FHV (Uber/Lyft) trip records. Data is for the years 2022-2024. This is the first notebook in a pipeline where data will be validated, analyzed for demand patterns, and used to build zone-level forecasting models. \n",
    "\n",
    "**Pipeline Position:** Notebook 1 of 4: Data Download\n",
    "\n",
    "- 00_data_download.ipynb ← **this notebook**\n",
    "- 01_data_validation.ipynb\n",
    "- 02_exploratory_analysis.ipynb\n",
    "- 03_demand_forecasting.ipynb\n",
    "\n",
    "**Objective:** The notebook acquires and consolidates the initial dataset that will be used for validation, exploration, and modeling stages.\n",
    "\n",
    "**Technical Approach:**\n",
    "- Build list of monthly file URLs for 2022–2024\n",
    "- Download each Parquet file (skip existing)\n",
    "- Consolidate files using DuckDB\n",
    "- Download zone metadata for later analysis\n",
    "\n",
    "**Inputs:**\n",
    "- 2022–2024 NYC TLC FHVHV trip data (publicly available from NYC Open Data)\n",
    "\n",
    "**Outputs:**\n",
    "- `data\\raw\\combined_fhvhv_tripdata.parquet`  (~18GB total)\n",
    "- `data\\raw\\zone_metadata.csv` — Zone reference data\n",
    "\n",
    "**Runtime:** ~1 hour first run; skips existing files on rerun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configure Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from pathlib import Path\n",
    "import duckdb\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Set Display and Plot Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Set Paths and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Config loaded: FHVHV 2022-2024\n"
     ]
    }
   ],
   "source": [
    "# Project Constants\n",
    "PROJECT_YEARS = [2022, 2023, 2024]\n",
    "TLC_DATASET = 'fhvhv'\n",
    "\n",
    "# Paths\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "RAW_DIR = PROJECT_ROOT / \"data\" / \"raw\"  # Source files + combined dataset\n",
    "\n",
    "# Notebook Configuration\n",
    "BASE_URL = \"https://d37ci6vzurychx.cloudfront.net/trip-data\"\n",
    "OUTPUT_FILE = RAW_DIR / f\"combined_{TLC_DATASET}_tripdata.parquet\"\n",
    "\n",
    "# Create Directory\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download Data\n",
    "Creates file list, downloads monthly trip files, and retrieves zone metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Create File List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Generated list of 36 files to download\n"
     ]
    }
   ],
   "source": [
    "# Generate list of files to download using year and month combinations in PROJECT_YEARS\n",
    "files_to_download = [\n",
    "    f\"{TLC_DATASET}_tripdata_{year}-{month:02d}.parquet\"\n",
    "    for year in PROJECT_YEARS\n",
    "    for month in range(1, 13)\n",
    "]\n",
    "\n",
    "print(f\"Generated list of {len(files_to_download)} files to download\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Download Trip Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/36] fhvhv_tripdata_2022-01.parquet... \n",
      "[2/36] fhvhv_tripdata_2022-02.parquet... \n",
      "[3/36] fhvhv_tripdata_2022-03.parquet... \n",
      "[4/36] fhvhv_tripdata_2022-04.parquet... \n",
      "[5/36] fhvhv_tripdata_2022-05.parquet... \n",
      "[6/36] fhvhv_tripdata_2022-06.parquet... \n",
      "[7/36] fhvhv_tripdata_2022-07.parquet... \n",
      "[8/36] fhvhv_tripdata_2022-08.parquet... \n",
      "[9/36] fhvhv_tripdata_2022-09.parquet... \n",
      "[10/36] fhvhv_tripdata_2022-10.parquet... \n",
      "[11/36] fhvhv_tripdata_2022-11.parquet... \n",
      "[12/36] fhvhv_tripdata_2022-12.parquet... \n",
      "[13/36] fhvhv_tripdata_2023-01.parquet... \n",
      "[14/36] fhvhv_tripdata_2023-02.parquet... \n",
      "[15/36] fhvhv_tripdata_2023-03.parquet... \n",
      "[16/36] fhvhv_tripdata_2023-04.parquet... \n",
      "[17/36] fhvhv_tripdata_2023-05.parquet... \n",
      "[18/36] fhvhv_tripdata_2023-06.parquet... \n",
      "[19/36] fhvhv_tripdata_2023-07.parquet... \n",
      "[20/36] fhvhv_tripdata_2023-08.parquet... \n",
      "[21/36] fhvhv_tripdata_2023-09.parquet... \n",
      "[22/36] fhvhv_tripdata_2023-10.parquet... \n",
      "[23/36] fhvhv_tripdata_2023-11.parquet... \n",
      "[24/36] fhvhv_tripdata_2023-12.parquet... \n",
      "[25/36] fhvhv_tripdata_2024-01.parquet... \n",
      "[26/36] fhvhv_tripdata_2024-02.parquet... \n",
      "[27/36] fhvhv_tripdata_2024-03.parquet... \n",
      "[28/36] fhvhv_tripdata_2024-04.parquet... \n",
      "[29/36] fhvhv_tripdata_2024-05.parquet... \n",
      "[30/36] fhvhv_tripdata_2024-06.parquet... \n",
      "[31/36] fhvhv_tripdata_2024-07.parquet... \n",
      "[32/36] fhvhv_tripdata_2024-08.parquet... \n",
      "[33/36] fhvhv_tripdata_2024-09.parquet... \n",
      "[34/36] fhvhv_tripdata_2024-10.parquet... \n",
      "[35/36] fhvhv_tripdata_2024-11.parquet... \n",
      "[36/36] fhvhv_tripdata_2024-12.parquet... \n",
      "\n",
      "Download complete: 36 files available\n"
     ]
    }
   ],
   "source": [
    "# Download files in list of files_to_download created above \n",
    "downloaded_files = []\n",
    "failed_files = []\n",
    "\n",
    "for i, filename in enumerate(files_to_download, 1):\n",
    "    url = f\"{BASE_URL}/{filename}\"\n",
    "    save_path = RAW_DIR / filename\n",
    "    \n",
    "    # Skip files that already exist\n",
    "    if save_path.exists():\n",
    "        downloaded_files.append(save_path)\n",
    "        continue\n",
    "    \n",
    "    # Download with error handling\n",
    "    try:\n",
    "        print(f\"[{i}/{len(files_to_download)}] {filename}...\", end=\" \")\n",
    "        urllib.request.urlretrieve(url, save_path)\n",
    "        downloaded_files.append(save_path)\n",
    "        print(\"\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ {str(e)[:50]}\")\n",
    "        failed_files.append(filename)\n",
    "\n",
    "# Summary\n",
    "print(f\"\\nDownload complete: {len(downloaded_files)} files available\")\n",
    "if failed_files:\n",
    "    print(f\"Failed: {len(failed_files)} files (may not exist yet)\")\n",
    "    for fname in failed_files[:5]:\n",
    "        print(f\"  - {fname}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Download Zone Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zone metadata saved: C:\\Users\\kristi\\OneDrive\\GitHub Repositories\\DataScienceProjects\\nyc-fhv-rideshare-forecasting\\data\\raw\\zone_metadata.csv\n",
      "Total zones: 265\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zone_id</th>\n",
       "      <th>Borough</th>\n",
       "      <th>Zone</th>\n",
       "      <th>service_zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>EWR</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>EWR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Queens</td>\n",
       "      <td>Jamaica Bay</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>Allerton/Pelham Gardens</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Alphabet City</td>\n",
       "      <td>Yellow Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>Arden Heights</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   zone_id        Borough                     Zone service_zone\n",
       "0        1            EWR           Newark Airport          EWR\n",
       "1        2         Queens              Jamaica Bay    Boro Zone\n",
       "2        3          Bronx  Allerton/Pelham Gardens    Boro Zone\n",
       "3        4      Manhattan            Alphabet City  Yellow Zone\n",
       "4        5  Staten Island            Arden Heights    Boro Zone"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NYC TLC zone metadata for zone names and boroughs \n",
    "\n",
    "zone_metadata_url = \"https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv\"\n",
    "zone_metadata_file = RAW_DIR / \"zone_metadata.csv\"\n",
    "\n",
    "if not zone_metadata_file.exists():\n",
    "    urllib.request.urlretrieve(zone_metadata_url, zone_metadata_file)\n",
    "    \n",
    "    # Rename LocationID column to zone_id for consistency\n",
    "    zone_metadata = pd.read_csv(zone_metadata_file)\n",
    "    zone_metadata = zone_metadata.rename(columns={'LocationID': 'zone_id'})\n",
    "    zone_metadata.to_csv(zone_metadata_file, index=False)\n",
    "    print(f\"Zone metadata saved: {zone_metadata_file}\")\n",
    "else:\n",
    "    zone_metadata = pd.read_csv(zone_metadata_file)\n",
    "    print(f\"Zone metadata exists, skipping download\")\n",
    "\n",
    "print(f\"Total zones: {len(zone_metadata)}\")\n",
    "zone_metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Combine Data \n",
    "Use DuckDB to combines all monthly files into a single dataset. \n",
    "(~5-10 minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Initialize DuckDB Connection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ DuckDB connection established\n"
     ]
    }
   ],
   "source": [
    "# Initialize DuckDB connection with memory-efficient settings\n",
    "con = duckdb.connect()\n",
    "con.execute(\"SET threads=4\")\n",
    "con.execute(\"SET preserve_insertion_order=false\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Combine Data Files\n",
    "Prepare file list for combining all downloaded monthly trip files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining 36 files and saving to: combined_fhvhv_tripdata.parquet...\n",
      "Saved: 18830.1 MB (18.39 GB)\n"
     ]
    }
   ],
   "source": [
    "# Create SQL-formatted file list from downloaded files\n",
    "file_list_sql = \", \".join([f\"'{str(f)}'\" for f in downloaded_files])\n",
    "\n",
    "print(f\"Prepared {len(downloaded_files)} files for combination:\")\n",
    "print(f\"  Output: {OUTPUT_FILE.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all monthly files into single parquet file\n",
    "print(f\"Combining {len(downloaded_files)} files...\")\n",
    "con.execute(f\"\"\"\n",
    "    COPY (\n",
    "        SELECT * FROM read_parquet([{file_list_sql}])\n",
    "    )\n",
    "    TO '{str(OUTPUT_FILE)}'\n",
    "    (FORMAT PARQUET, COMPRESSION SNAPPY)\n",
    "\"\"\")\n",
    "\n",
    "# Verify export\n",
    "parquet_file_size_mb = OUTPUT_FILE.stat().st_size / 1024**2\n",
    "print(f\"Export complete: {parquet_file_size_mb:.1f} MB ({parquet_file_size_mb/1024:.2f} GB)\")\n",
    "print(f\"  Location: {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Verify Dataset Structure\n",
    "Confirms the combined dataset has the correct schema, expected row counts, and date range coverage and validates presence of fields required for downstream analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Validate Schema and Critical Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query dataset metrics\n",
    "summary = con.execute(f\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as row_count,\n",
    "        MIN(pickup_datetime) as start_date,\n",
    "        MAX(pickup_datetime) as end_date\n",
    "    FROM '{OUTPUT_FILE}'\n",
    "\"\"\").fetchone()\n",
    "\n",
    "row_count, start_date, end_date = summary\n",
    "\n",
    "# Get schema information\n",
    "columns = con.execute(f\"DESCRIBE SELECT * FROM '{OUTPUT_FILE}'\").df()\n",
    "column_names = columns['column_name'].tolist()\n",
    "\n",
    "# Verify critical columns needed analysis are present\n",
    "expected_columns = [\n",
    "    'hvfhs_license_num',\n",
    "    'pickup_datetime',        \n",
    "    'dropoff_datetime',       \n",
    "    'PULocationID',           \n",
    "    'DOLocationID',           \n",
    "    'trip_miles',             \n",
    "    'trip_time',              \n",
    "    'base_passenger_fare'     \n",
    "]\n",
    "\n",
    "# Assert all present\n",
    "missing = [col for col in expected_columns if col not in column_names]\n",
    "assert len(missing) == 0, f\"Schema validation failed - missing columns: {missing}\"\n",
    "\n",
    "print(f\"Schema validation complete: {row_count:,} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display dataset summary and schema validation results\n",
    "print(\"DATASET STRUCTURE VERIFICATION\")\n",
    "print(\"_\"*60)\n",
    "print(f\"\\nRows:        {row_count:,}\")\n",
    "print(f\"Columns:     {len(column_names)}\")\n",
    "print(f\"Date range:  {start_date} to {end_date}\")\n",
    "print(f\"File size:   {parquet_file_size_mb:.1f} MB ({parquet_file_size_mb/1024:.2f} GB)\")\n",
    "\n",
    "print(f\"\\nCritical pipeline fields validated:\")\n",
    "for col in expected_columns:\n",
    "    status = \"✓\" if col in column_names else \"✗ MISSING\"\n",
    "    print(f\"  {status} {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Review Full Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>column_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hvfhs_license_num</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dispatching_base_num</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>originating_base_num</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>request_datetime</td>\n",
       "      <td>TIMESTAMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>on_scene_datetime</td>\n",
       "      <td>TIMESTAMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pickup_datetime</td>\n",
       "      <td>TIMESTAMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dropoff_datetime</td>\n",
       "      <td>TIMESTAMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PULocationID</td>\n",
       "      <td>BIGINT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DOLocationID</td>\n",
       "      <td>BIGINT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>trip_miles</td>\n",
       "      <td>DOUBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>trip_time</td>\n",
       "      <td>BIGINT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>base_passenger_fare</td>\n",
       "      <td>DOUBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tolls</td>\n",
       "      <td>DOUBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bcf</td>\n",
       "      <td>DOUBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sales_tax</td>\n",
       "      <td>DOUBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>congestion_surcharge</td>\n",
       "      <td>DOUBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>airport_fee</td>\n",
       "      <td>DOUBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tips</td>\n",
       "      <td>DOUBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>driver_pay</td>\n",
       "      <td>DOUBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>shared_request_flag</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>shared_match_flag</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>access_a_ride_flag</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>wav_request_flag</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>wav_match_flag</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             column_name column_type\n",
       "0      hvfhs_license_num     VARCHAR\n",
       "1   dispatching_base_num     VARCHAR\n",
       "2   originating_base_num     VARCHAR\n",
       "3       request_datetime   TIMESTAMP\n",
       "4      on_scene_datetime   TIMESTAMP\n",
       "5        pickup_datetime   TIMESTAMP\n",
       "6       dropoff_datetime   TIMESTAMP\n",
       "7           PULocationID      BIGINT\n",
       "8           DOLocationID      BIGINT\n",
       "9             trip_miles      DOUBLE\n",
       "10             trip_time      BIGINT\n",
       "11   base_passenger_fare      DOUBLE\n",
       "12                 tolls      DOUBLE\n",
       "13                   bcf      DOUBLE\n",
       "14             sales_tax      DOUBLE\n",
       "15  congestion_surcharge      DOUBLE\n",
       "16           airport_fee      DOUBLE\n",
       "17                  tips      DOUBLE\n",
       "18            driver_pay      DOUBLE\n",
       "19   shared_request_flag     VARCHAR\n",
       "20     shared_match_flag     VARCHAR\n",
       "21    access_a_ride_flag     VARCHAR\n",
       "22      wav_request_flag     VARCHAR\n",
       "23        wav_match_flag     VARCHAR"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all columns with data types\n",
    "con.execute(f\"DESCRIBE SELECT * FROM '{OUTPUT_FILE}'\").df()[['column_name', 'column_type']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Preview Sample Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hvfhs_license_num</th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>originating_base_num</th>\n",
       "      <th>request_datetime</th>\n",
       "      <th>on_scene_datetime</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>trip_time</th>\n",
       "      <th>base_passenger_fare</th>\n",
       "      <th>tolls</th>\n",
       "      <th>bcf</th>\n",
       "      <th>sales_tax</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>tips</th>\n",
       "      <th>driver_pay</th>\n",
       "      <th>shared_request_flag</th>\n",
       "      <th>shared_match_flag</th>\n",
       "      <th>access_a_ride_flag</th>\n",
       "      <th>wav_request_flag</th>\n",
       "      <th>wav_match_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2022-01-01 00:05:31</td>\n",
       "      <td>2022-01-01 00:05:40</td>\n",
       "      <td>2022-01-01 00:07:24</td>\n",
       "      <td>2022-01-01 00:18:28</td>\n",
       "      <td>170</td>\n",
       "      <td>161</td>\n",
       "      <td>1.18</td>\n",
       "      <td>664</td>\n",
       "      <td>24.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.21</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.03</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2022-01-01 00:19:27</td>\n",
       "      <td>2022-01-01 00:22:08</td>\n",
       "      <td>2022-01-01 00:22:32</td>\n",
       "      <td>2022-01-01 00:30:12</td>\n",
       "      <td>237</td>\n",
       "      <td>161</td>\n",
       "      <td>0.82</td>\n",
       "      <td>460</td>\n",
       "      <td>11.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.06</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.32</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2022-01-01 00:43:53</td>\n",
       "      <td>2022-01-01 00:57:37</td>\n",
       "      <td>2022-01-01 00:57:37</td>\n",
       "      <td>2022-01-01 01:07:32</td>\n",
       "      <td>237</td>\n",
       "      <td>161</td>\n",
       "      <td>1.18</td>\n",
       "      <td>595</td>\n",
       "      <td>29.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.30</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2022-01-01 00:15:36</td>\n",
       "      <td>2022-01-01 00:17:08</td>\n",
       "      <td>2022-01-01 00:18:02</td>\n",
       "      <td>2022-01-01 00:23:05</td>\n",
       "      <td>262</td>\n",
       "      <td>229</td>\n",
       "      <td>1.65</td>\n",
       "      <td>303</td>\n",
       "      <td>7.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.30</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2022-01-01 00:25:45</td>\n",
       "      <td>2022-01-01 00:26:01</td>\n",
       "      <td>2022-01-01 00:28:01</td>\n",
       "      <td>2022-01-01 00:35:42</td>\n",
       "      <td>229</td>\n",
       "      <td>141</td>\n",
       "      <td>1.65</td>\n",
       "      <td>461</td>\n",
       "      <td>9.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.84</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.44</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  hvfhs_license_num dispatching_base_num originating_base_num  \\\n",
       "0            HV0003               B03404               B03404   \n",
       "1            HV0003               B03404               B03404   \n",
       "2            HV0003               B03404               B03404   \n",
       "3            HV0003               B03404               B03404   \n",
       "4            HV0003               B03404               B03404   \n",
       "\n",
       "     request_datetime   on_scene_datetime     pickup_datetime  \\\n",
       "0 2022-01-01 00:05:31 2022-01-01 00:05:40 2022-01-01 00:07:24   \n",
       "1 2022-01-01 00:19:27 2022-01-01 00:22:08 2022-01-01 00:22:32   \n",
       "2 2022-01-01 00:43:53 2022-01-01 00:57:37 2022-01-01 00:57:37   \n",
       "3 2022-01-01 00:15:36 2022-01-01 00:17:08 2022-01-01 00:18:02   \n",
       "4 2022-01-01 00:25:45 2022-01-01 00:26:01 2022-01-01 00:28:01   \n",
       "\n",
       "     dropoff_datetime  PULocationID  DOLocationID  trip_miles  trip_time  \\\n",
       "0 2022-01-01 00:18:28           170           161        1.18        664   \n",
       "1 2022-01-01 00:30:12           237           161        0.82        460   \n",
       "2 2022-01-01 01:07:32           237           161        1.18        595   \n",
       "3 2022-01-01 00:23:05           262           229        1.65        303   \n",
       "4 2022-01-01 00:35:42           229           141        1.65        461   \n",
       "\n",
       "   base_passenger_fare  tolls   bcf  sales_tax  congestion_surcharge  \\\n",
       "0                24.90    0.0  0.75       2.21                  2.75   \n",
       "1                11.97    0.0  0.36       1.06                  2.75   \n",
       "2                29.82    0.0  0.89       2.65                  2.75   \n",
       "3                 7.91    0.0  0.24       0.70                  2.75   \n",
       "4                 9.44    0.0  0.28       0.84                  2.75   \n",
       "\n",
       "   airport_fee  tips  driver_pay shared_request_flag shared_match_flag  \\\n",
       "0          0.0   0.0       23.03                   N                 N   \n",
       "1          0.0   0.0       12.32                   N                 N   \n",
       "2          0.0   0.0       23.30                   N                 N   \n",
       "3          0.0   0.0        6.30                   N                 N   \n",
       "4          0.0   0.0        7.44                   N                 N   \n",
       "\n",
       "  access_a_ride_flag wav_request_flag wav_match_flag  \n",
       "0                                   N              N  \n",
       "1                                   N              N  \n",
       "2                                   N              N  \n",
       "3                                   N              N  \n",
       "4                                   N              N  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display sample records in transposed format\n",
    "sample_df = con.execute(f\"\"\"\n",
    "    SELECT * FROM '{OUTPUT_FILE}' LIMIT 4\n",
    "\"\"\").df()\n",
    "\n",
    "# Preview sample records\n",
    "con.execute(f\"SELECT * FROM '{OUTPUT_FILE}' LIMIT 5\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Complete\n"
     ]
    }
   ],
   "source": [
    "# Close DuckDB connection and release resources and file locks\n",
    "con.close()\n",
    "print(\"\\n Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset Summary:**\n",
    "- 684 million records\n",
    "- 36 files downloaded (Jan 2022 - Dec 2024)\n",
    "- All expected columns present\n",
    "\n",
    "Data is ready for validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook downloaded and consolidated 36 monthly files of NYC TLC FHVHV trip data, creating a single 18GB dataset with 684 million records spanning 2022-2024.\n",
    "\n",
    "**Key Findings:**\n",
    "- Successfully downloaded all 36 monthly files (Jan 2022 - Dec 2024)\n",
    "- Date range verified: 2022-01-01 to 2024-12-31\n",
    "- All expected critical columns present in combined dataset\n",
    "\n",
    "**Technical Decisions:**\n",
    "- Used DuckDB instead of Pandas to handle 18GB dataset (avoided memory errors)\n",
    "- Optimized DuckDB settings (`threads=4`, `preserve_insertion_order=false`) reduced combination time from 30+ to 6 minutes\n",
    "- Renamed `LocationID` to `zone_id` in metadata for downstream consistency\n",
    "- Parquet format with Snappy compression for efficient storage\n",
    "\n",
    "**Outputs:**\n",
    "- `data/raw/combined_fhvhv_tripdata.parquet` — Combined dataset (18.4 GB, 684M records)\n",
    "- `data/raw/zone_metadata.csv` — Zone reference data (263 zones)\n",
    "\n",
    "**Next Steps:**\n",
    "Proceed to **01_data_validation.ipynb** to validate data quality and flag records for analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
