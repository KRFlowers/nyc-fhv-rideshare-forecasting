{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYC Rideshare Forecasting Pipeline - Part 1: Data Download\n",
    "\n",
    "**Author:** K Flowers  \n",
    "**GitHub:** [github.com/KRFlowers](https://github.com/KRFlowers)  \n",
    "**Date:** December 2025\n",
    "\n",
    "This notebook downloads 36 months of NYC Taxi & Limousine Commission (TLC) High Volume FHV (Uber/Lyft) trip records. Data is for the years 2022-2024. The data covers the years 2022–2024. This notebook is the first step in a pipeline, with subsequent notebooks focused on data validation, exploratory data analysis (EDA), and forecasting.\n",
    "\n",
    "**Pipeline Position:** Notebook 1 of 4: Data Download\n",
    "\n",
    "- 00_data_download.ipynb ← **this notebook**\n",
    "- 01_data_validation.ipynb\n",
    "- 02_exploratory_analysis.ipynb\n",
    "- 03_demand_forecasting.ipynb\n",
    "\n",
    "**Objective:** The notebook acquires and consolidates the initial dataset that will be used for validation, exploration, and modeling stages.\n",
    "\n",
    "**Technical Approach:**\n",
    "- Build list of monthly file URLs for 2022–2024\n",
    "- Download each Parquet file (skip existing)\n",
    "- Consolidate files using DuckDB\n",
    "- Download zone metadata for later analysis\n",
    "\n",
    "**Inputs:**\n",
    "- 36 monthly files — 2022–2024 NYC TLC FHVHV trip data (from NYC Open Data)\n",
    "\n",
    "**Outputs:**\n",
    "- `data\\raw\\combined_fhvhv_tripdata.parquet` -  Combined trip data (~18GB)\n",
    "- `data\\raw\\zone_metadata.csv` - Zone reference data\n",
    "\n",
    "**Runtime:** ~1 hour first run; skips existing files on rerun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configure Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from pathlib import Path\n",
    "import duckdb\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Set Display and Plot Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Set Paths and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project Constants\n",
    "PROJECT_YEARS = [2022, 2023, 2024]\n",
    "TLC_DATASET = 'fhvhv'\n",
    "\n",
    "# Paths\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "RAW_DIR = PROJECT_ROOT / \"data\" / \"raw\"  # Source files + combined dataset\n",
    "\n",
    "# Notebook Configuration\n",
    "BASE_URL = \"https://d37ci6vzurychx.cloudfront.net/trip-data\"\n",
    "OUTPUT_FILE = RAW_DIR / f\"combined_{TLC_DATASET}_tripdata.parquet\"\n",
    "\n",
    "# Create Directory\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download Data\n",
    "Creates the list of monthly files to download, downloads files, and retrieves zone metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Create File List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated list of 36 files to download\n"
     ]
    }
   ],
   "source": [
    "# Generate list of files to download using year and month combinations in PROJECT_YEARS\n",
    "files_to_download = [\n",
    "    f\"{TLC_DATASET}_tripdata_{year}-{month:02d}.parquet\"\n",
    "    for year in PROJECT_YEARS\n",
    "    for month in range(1, 13)\n",
    "]\n",
    "\n",
    "print(f\"Created list of {len(files_to_download)} files to download\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Download Trip Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Download complete: 36 files available\n"
     ]
    }
   ],
   "source": [
    "# Download files in files_to_download list\n",
    "downloaded_files = []\n",
    "failed_files = []\n",
    "\n",
    "for i, filename in enumerate(files_to_download, 1):\n",
    "    url = f\"{BASE_URL}/{filename}\"\n",
    "    save_path = RAW_DIR / filename\n",
    "    \n",
    "    # Skip files that already exist\n",
    "    if save_path.exists():\n",
    "        downloaded_files.append(save_path)\n",
    "        continue\n",
    "    \n",
    "    # Download with error handling\n",
    "    try:\n",
    "        print(f\"[{i}/{len(files_to_download)}] {filename}...\", end=\" \")\n",
    "        urllib.request.urlretrieve(url, save_path)\n",
    "        downloaded_files.append(save_path)\n",
    "        print(\"\")\n",
    "    except Exception as e:\n",
    "        print(f\"FAILED: {str(e)[:50]}\")\n",
    "        failed_files.append(filename)\n",
    "\n",
    "\n",
    "print(f\"\\nDownload complete: {len(downloaded_files)} files available\")\n",
    "if failed_files:\n",
    "    print(f\"Failed: {len(failed_files)} files (may not exist yet)\")\n",
    "    for fname in failed_files[:5]:\n",
    "        print(f\"  - {fname}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Download Zone Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zone metadata exists, skipping download\n",
      "Total zones: 265\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zone_id</th>\n",
       "      <th>Borough</th>\n",
       "      <th>Zone</th>\n",
       "      <th>service_zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>EWR</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>EWR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Queens</td>\n",
       "      <td>Jamaica Bay</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>Allerton/Pelham Gardens</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Alphabet City</td>\n",
       "      <td>Yellow Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>Arden Heights</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   zone_id        Borough                     Zone service_zone\n",
       "0        1            EWR           Newark Airport          EWR\n",
       "1        2         Queens              Jamaica Bay    Boro Zone\n",
       "2        3          Bronx  Allerton/Pelham Gardens    Boro Zone\n",
       "3        4      Manhattan            Alphabet City  Yellow Zone\n",
       "4        5  Staten Island            Arden Heights    Boro Zone"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NYC TLC zone metadata for zone names and boroughs \n",
    "\n",
    "zone_metadata_url = \"https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv\"\n",
    "zone_metadata_file = RAW_DIR / \"zone_metadata.csv\"\n",
    "\n",
    "if not zone_metadata_file.exists():\n",
    "    urllib.request.urlretrieve(zone_metadata_url, zone_metadata_file)\n",
    "    \n",
    "    # Rename LocationID column to zone_id for consistency\n",
    "    zone_metadata = pd.read_csv(zone_metadata_file)\n",
    "    zone_metadata = zone_metadata.rename(columns={'LocationID': 'zone_id'})\n",
    "    zone_metadata.to_csv(zone_metadata_file, index=False)\n",
    "    print(f\"Zone metadata saved: {zone_metadata_file}\")\n",
    "else:\n",
    "    zone_metadata = pd.read_csv(zone_metadata_file)\n",
    "    print(f\"Zone metadata exists, skipping download\")\n",
    "\n",
    "print(f\"Total zones: {len(zone_metadata)}\")\n",
    "zone_metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Combine Data \n",
    "Combine all monthly files into a single dataset using DuckDB\n",
    "(~5-10 minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Initialize DuckDB Connection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_duckdb.DuckDBPyConnection at 0x1689e3fcb70>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize DuckDB connection, use memory-efficient settings\n",
    "con = duckdb.connect()\n",
    "con.execute(\"SET threads=4\")\n",
    "con.execute(\"SET preserve_insertion_order=false\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Combine Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 36 files for combination:\n",
      "  Output: combined_fhvhv_tripdata.parquet\n"
     ]
    }
   ],
   "source": [
    "# Create SQL-formatted file list from downloaded files\n",
    "file_list_sql = \", \".join([f\"'{str(f)}'\" for f in downloaded_files])\n",
    "\n",
    "print(f\"Prepared {len(downloaded_files)} files for combination:\")\n",
    "print(f\"  Output: {OUTPUT_FILE.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining 36 files...\n",
      "Export complete: 18830.7 MB (18.39 GB)\n",
      "  Location: C:\\Users\\kristi\\OneDrive\\04_GitHub_Projects\\Data Science Projects\\nyc-fhv-rideshare-forecasting\\data\\raw\\combined_fhvhv_tripdata.parquet\n"
     ]
    }
   ],
   "source": [
    "# Combine all monthly files into single parquet file\n",
    "print(f\"Combining {len(downloaded_files)} files...\")\n",
    "con.execute(f\"\"\"\n",
    "    COPY (\n",
    "        SELECT * FROM read_parquet([{file_list_sql}])\n",
    "    )\n",
    "    TO '{str(OUTPUT_FILE)}'\n",
    "    (FORMAT PARQUET, COMPRESSION SNAPPY)\n",
    "\"\"\")\n",
    "\n",
    "# Verify export\n",
    "parquet_file_size_mb = OUTPUT_FILE.stat().st_size / 1024**2\n",
    "print(f\"Export complete: {parquet_file_size_mb:.1f} MB ({parquet_file_size_mb/1024:.2f} GB)\")\n",
    "print(f\"  Location: {OUTPUT_FILE.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Verify Dataset Structure\n",
    "Confirms the combined dataset has the correct schema, expected row counts, date range coverage and fields required for downstream analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Validate Schema and Critical Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema validation complete: 684,376,551 records\n"
     ]
    }
   ],
   "source": [
    "# Query dataset metrics\n",
    "summary = con.execute(f\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as row_count,\n",
    "        MIN(pickup_datetime) as start_date,\n",
    "        MAX(pickup_datetime) as end_date\n",
    "    FROM '{OUTPUT_FILE}'\n",
    "\"\"\").fetchone()\n",
    "\n",
    "row_count, start_date, end_date = summary\n",
    "\n",
    "# Get schema information\n",
    "columns = con.execute(f\"DESCRIBE SELECT * FROM '{OUTPUT_FILE}'\").df()\n",
    "column_names = columns['column_name'].tolist()\n",
    "\n",
    "# Verify critical columns needed analysis are present\n",
    "expected_columns = [\n",
    "    'hvfhs_license_num',\n",
    "    'pickup_datetime',        \n",
    "    'dropoff_datetime',       \n",
    "    'PULocationID',           \n",
    "    'DOLocationID',           \n",
    "    'trip_miles',             \n",
    "    'trip_time',              \n",
    "    'base_passenger_fare'     \n",
    "]\n",
    "\n",
    "# Assert all present\n",
    "missing = [col for col in expected_columns if col not in column_names]\n",
    "assert len(missing) == 0, f\"Schema validation failed - missing columns: {missing}\"\n",
    "\n",
    "print(f\"Schema validation complete: {row_count:,} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET STRUCTURE VERIFICATION\n",
      "____________________________________________________________\n",
      "\n",
      "Rows:        684,376,551\n",
      "Columns:     24\n",
      "Date range:  2022-01-01 00:00:00 to 2024-12-31 23:59:59\n",
      "File size:   18830.7 MB (18.39 GB)\n",
      "\n",
      "Critical pipeline fields validated:\n",
      "  [OK] hvfhs_license_num\n",
      "  [OK] pickup_datetime\n",
      "  [OK] dropoff_datetime\n",
      "  [OK] PULocationID\n",
      "  [OK] DOLocationID\n",
      "  [OK] trip_miles\n",
      "  [OK] trip_time\n",
      "  [OK] base_passenger_fare\n"
     ]
    }
   ],
   "source": [
    "# Display dataset summary and schema validation results\n",
    "print(\"DATASET STRUCTURE VERIFICATION\")\n",
    "print(\"_\"*60)\n",
    "print(f\"\\nRows:        {row_count:,}\")\n",
    "print(f\"Columns:     {len(column_names)}\")\n",
    "print(f\"Date range:  {start_date} to {end_date}\")\n",
    "print(f\"File size:   {parquet_file_size_mb:.1f} MB ({parquet_file_size_mb/1024:.2f} GB)\")\n",
    "\n",
    "print(f\"\\nCritical pipeline fields validated:\")\n",
    "for col in expected_columns:\n",
    "    status = \"OK\" if col in column_names else \"MISSING\"\n",
    "    print(f\"  [{status}] {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Review Full Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>column_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hvfhs_license_num</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dispatching_base_num</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>originating_base_num</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>request_datetime</td>\n",
       "      <td>TIMESTAMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>on_scene_datetime</td>\n",
       "      <td>TIMESTAMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pickup_datetime</td>\n",
       "      <td>TIMESTAMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dropoff_datetime</td>\n",
       "      <td>TIMESTAMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PULocationID</td>\n",
       "      <td>BIGINT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DOLocationID</td>\n",
       "      <td>BIGINT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>trip_miles</td>\n",
       "      <td>DOUBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>trip_time</td>\n",
       "      <td>BIGINT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>base_passenger_fare</td>\n",
       "      <td>DOUBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tolls</td>\n",
       "      <td>DOUBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bcf</td>\n",
       "      <td>DOUBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sales_tax</td>\n",
       "      <td>DOUBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>congestion_surcharge</td>\n",
       "      <td>DOUBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>airport_fee</td>\n",
       "      <td>DOUBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tips</td>\n",
       "      <td>DOUBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>driver_pay</td>\n",
       "      <td>DOUBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>shared_request_flag</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>shared_match_flag</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>access_a_ride_flag</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>wav_request_flag</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>wav_match_flag</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             column_name column_type\n",
       "0      hvfhs_license_num     VARCHAR\n",
       "1   dispatching_base_num     VARCHAR\n",
       "2   originating_base_num     VARCHAR\n",
       "3       request_datetime   TIMESTAMP\n",
       "4      on_scene_datetime   TIMESTAMP\n",
       "5        pickup_datetime   TIMESTAMP\n",
       "6       dropoff_datetime   TIMESTAMP\n",
       "7           PULocationID      BIGINT\n",
       "8           DOLocationID      BIGINT\n",
       "9             trip_miles      DOUBLE\n",
       "10             trip_time      BIGINT\n",
       "11   base_passenger_fare      DOUBLE\n",
       "12                 tolls      DOUBLE\n",
       "13                   bcf      DOUBLE\n",
       "14             sales_tax      DOUBLE\n",
       "15  congestion_surcharge      DOUBLE\n",
       "16           airport_fee      DOUBLE\n",
       "17                  tips      DOUBLE\n",
       "18            driver_pay      DOUBLE\n",
       "19   shared_request_flag     VARCHAR\n",
       "20     shared_match_flag     VARCHAR\n",
       "21    access_a_ride_flag     VARCHAR\n",
       "22      wav_request_flag     VARCHAR\n",
       "23        wav_match_flag     VARCHAR"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all columns with data types\n",
    "con.execute(f\"DESCRIBE SELECT * FROM '{OUTPUT_FILE}'\").df()[['column_name', 'column_type']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Preview Sample Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hvfhs_license_num</th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>originating_base_num</th>\n",
       "      <th>request_datetime</th>\n",
       "      <th>on_scene_datetime</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>trip_time</th>\n",
       "      <th>base_passenger_fare</th>\n",
       "      <th>tolls</th>\n",
       "      <th>bcf</th>\n",
       "      <th>sales_tax</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>tips</th>\n",
       "      <th>driver_pay</th>\n",
       "      <th>shared_request_flag</th>\n",
       "      <th>shared_match_flag</th>\n",
       "      <th>access_a_ride_flag</th>\n",
       "      <th>wav_request_flag</th>\n",
       "      <th>wav_match_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2022-01-01 00:05:31</td>\n",
       "      <td>2022-01-01 00:05:40</td>\n",
       "      <td>2022-01-01 00:07:24</td>\n",
       "      <td>2022-01-01 00:18:28</td>\n",
       "      <td>170</td>\n",
       "      <td>161</td>\n",
       "      <td>1.1800</td>\n",
       "      <td>664</td>\n",
       "      <td>24.9000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>2.2100</td>\n",
       "      <td>2.7500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>23.0300</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2022-01-01 00:19:27</td>\n",
       "      <td>2022-01-01 00:22:08</td>\n",
       "      <td>2022-01-01 00:22:32</td>\n",
       "      <td>2022-01-01 00:30:12</td>\n",
       "      <td>237</td>\n",
       "      <td>161</td>\n",
       "      <td>0.8200</td>\n",
       "      <td>460</td>\n",
       "      <td>11.9700</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>1.0600</td>\n",
       "      <td>2.7500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>12.3200</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2022-01-01 00:43:53</td>\n",
       "      <td>2022-01-01 00:57:37</td>\n",
       "      <td>2022-01-01 00:57:37</td>\n",
       "      <td>2022-01-01 01:07:32</td>\n",
       "      <td>237</td>\n",
       "      <td>161</td>\n",
       "      <td>1.1800</td>\n",
       "      <td>595</td>\n",
       "      <td>29.8200</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8900</td>\n",
       "      <td>2.6500</td>\n",
       "      <td>2.7500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>23.3000</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2022-01-01 00:15:36</td>\n",
       "      <td>2022-01-01 00:17:08</td>\n",
       "      <td>2022-01-01 00:18:02</td>\n",
       "      <td>2022-01-01 00:23:05</td>\n",
       "      <td>262</td>\n",
       "      <td>229</td>\n",
       "      <td>1.6500</td>\n",
       "      <td>303</td>\n",
       "      <td>7.9100</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>2.7500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>6.3000</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2022-01-01 00:25:45</td>\n",
       "      <td>2022-01-01 00:26:01</td>\n",
       "      <td>2022-01-01 00:28:01</td>\n",
       "      <td>2022-01-01 00:35:42</td>\n",
       "      <td>229</td>\n",
       "      <td>141</td>\n",
       "      <td>1.6500</td>\n",
       "      <td>461</td>\n",
       "      <td>9.4400</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>0.8400</td>\n",
       "      <td>2.7500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>7.4400</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  hvfhs_license_num dispatching_base_num originating_base_num  \\\n",
       "0            HV0003               B03404               B03404   \n",
       "1            HV0003               B03404               B03404   \n",
       "2            HV0003               B03404               B03404   \n",
       "3            HV0003               B03404               B03404   \n",
       "4            HV0003               B03404               B03404   \n",
       "\n",
       "     request_datetime   on_scene_datetime     pickup_datetime  \\\n",
       "0 2022-01-01 00:05:31 2022-01-01 00:05:40 2022-01-01 00:07:24   \n",
       "1 2022-01-01 00:19:27 2022-01-01 00:22:08 2022-01-01 00:22:32   \n",
       "2 2022-01-01 00:43:53 2022-01-01 00:57:37 2022-01-01 00:57:37   \n",
       "3 2022-01-01 00:15:36 2022-01-01 00:17:08 2022-01-01 00:18:02   \n",
       "4 2022-01-01 00:25:45 2022-01-01 00:26:01 2022-01-01 00:28:01   \n",
       "\n",
       "     dropoff_datetime  PULocationID  DOLocationID  trip_miles  trip_time  \\\n",
       "0 2022-01-01 00:18:28           170           161      1.1800        664   \n",
       "1 2022-01-01 00:30:12           237           161      0.8200        460   \n",
       "2 2022-01-01 01:07:32           237           161      1.1800        595   \n",
       "3 2022-01-01 00:23:05           262           229      1.6500        303   \n",
       "4 2022-01-01 00:35:42           229           141      1.6500        461   \n",
       "\n",
       "   base_passenger_fare  tolls    bcf  sales_tax  congestion_surcharge  \\\n",
       "0              24.9000 0.0000 0.7500     2.2100                2.7500   \n",
       "1              11.9700 0.0000 0.3600     1.0600                2.7500   \n",
       "2              29.8200 0.0000 0.8900     2.6500                2.7500   \n",
       "3               7.9100 0.0000 0.2400     0.7000                2.7500   \n",
       "4               9.4400 0.0000 0.2800     0.8400                2.7500   \n",
       "\n",
       "   airport_fee   tips  driver_pay shared_request_flag shared_match_flag  \\\n",
       "0       0.0000 0.0000     23.0300                   N                 N   \n",
       "1       0.0000 0.0000     12.3200                   N                 N   \n",
       "2       0.0000 0.0000     23.3000                   N                 N   \n",
       "3       0.0000 0.0000      6.3000                   N                 N   \n",
       "4       0.0000 0.0000      7.4400                   N                 N   \n",
       "\n",
       "  access_a_ride_flag wav_request_flag wav_match_flag  \n",
       "0                                   N              N  \n",
       "1                                   N              N  \n",
       "2                                   N              N  \n",
       "3                                   N              N  \n",
       "4                                   N              N  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display sample records in transposed format\n",
    "sample_df = con.execute(f\"\"\"\n",
    "    SELECT * FROM '{OUTPUT_FILE}' LIMIT 4\n",
    "\"\"\").df()\n",
    "\n",
    "# Preview sample records\n",
    "con.execute(f\"SELECT * FROM '{OUTPUT_FILE}' LIMIT 5\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Complete\n"
     ]
    }
   ],
   "source": [
    "# Close DuckDB connection and release resources and file locks\n",
    "con.close()\n",
    "print(\"\\n DuckDB connection closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook downloaded and consolidated 36 monthly files of NYC TLC FHVHV trip data, creating a single 18GB dataset with 684 million records spanning 2022-2024.\n",
    "\n",
    "**Key Findings:**\n",
    "- Successfully downloaded all 36 monthly files (Jan 2022 - Dec 2024)\n",
    "- Date range verified: 2022-01-01 to 2024-12-31\n",
    "- All expected critical columns present in combined dataset\n",
    "\n",
    "**Technical Decisions:**\n",
    "- Used DuckDB instead of Pandas to handle 18GB dataset (avoided memory errors)\n",
    "- Optimized DuckDB settings (`threads=4`, `preserve_insertion_order=false`) to reduce combination time from 30+ to 6 minutes\n",
    "- Renamed `LocationID` to `zone_id` in metadata for downstream consistency\n",
    "- Stored dataset as parquet with Snappy compression for efficient storage\n",
    "\n",
    "**Outputs:**\n",
    "- `data/raw/combined_fhvhv_tripdata.parquet` — Combined dataset (18.4 GB, 684M records)\n",
    "- `data/raw/zone_metadata.csv` — Zone reference data (263 zones)\n",
    "\n",
    "**Next Steps:**\n",
    "Proceed to **01_data_validation.ipynb** to validate data quality and flag records for analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
