{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FHVHV Data Pipeline - Stage 3: Demand Forecasting\n",
    "\n",
    "**Pipeline Position:** Stage 3 of 4\n",
    "\n",
    "- Stage 0: Data Download (Complete)\n",
    "- Stage 1: Data Validation (Complete)\n",
    "- Stage 2: Exploratory Analysis (Complete)\n",
    "- Stage 3: Modeling ← THIS NOTEBOOK\n",
    "\n",
    "**Objective:** Build and evaluate forecasting models to predict daily zone demand.\n",
    "\n",
    "**Models:** Baseline (Seasonal Naive), Prophet, XGBoost\n",
    "\n",
    "**Approach:** Develop on single zone → Evaluate → Scale to 100 zones\n",
    "\n",
    "**EDA Insights Applied:**\n",
    "- Weekend-dominant demand (17% higher) → models must capture weekly seasonality\n",
    "- Moderate yearly seasonality (13.7%) → Prophet will handle this\n",
    "- Low variability (CV < 0.3) → simpler models may perform well\n",
    "- 40% zone pairs highly correlated → potential for shared parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Setup\n",
    "\n",
    "Load libraries, data, and define evaluation metrics for model comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Modeling\n",
    "from prophet import Prophet\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Configuration\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plot styling\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams.update({\n",
    "    'figure.figsize': (12, 4),\n",
    "    'axes.titlesize': 10,\n",
    "    'axes.labelsize': 9,\n",
    "    'xtick.labelsize': 8,\n",
    "    'ytick.labelsize': 8\n",
    "})\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA LOADED\n",
      "========================================\n",
      "Zone-daily records: 109,600\n",
      "Zones: 100\n",
      "Date range: 2022-01-01 00:00:00 to 2024-12-31 00:00:00\n",
      "Columns: 28\n"
     ]
    }
   ],
   "source": [
    "# What: Load zone-daily aggregated data from EDA stage\n",
    "# Why: This is our modeling-ready dataset with time features\n",
    "\n",
    "DATA_DIR = Path(\"../data/processed\")\n",
    "\n",
    "zone_daily = pd.read_parquet(DATA_DIR / \"zone_daily.parquet\")\n",
    "selected_zones = pd.read_csv(DATA_DIR / \"zone_metadata.csv\")\n",
    "\n",
    "print(\"DATA LOADED\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Zone-daily records: {len(zone_daily):,}\")\n",
    "print(f\"Zones: {zone_daily['zone_id'].nunique()}\")\n",
    "print(f\"Date range: {zone_daily['date'].min()} to {zone_daily['date'].max()}\")\n",
    "print(f\"Columns: {len(zone_daily.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3 Define Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation function defined\n",
      "Metrics: MAE (Mean Absolute Error), RMSE (Root Mean Squared Error), MAPE (Mean Absolute Percentage Error)\n"
     ]
    }
   ],
   "source": [
    "# What: Create evaluation function for consistent model comparison\n",
    "# Why: Need standard metrics across all models (MAE, RMSE, MAPE)\n",
    "\n",
    "def evaluate_forecast(actual, predicted, model_name=\"Model\"):\n",
    "    \"\"\"Calculate forecast accuracy metrics.\"\"\"\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    rmse = np.sqrt(mean_squared_error(actual, predicted))\n",
    "    mape = np.mean(np.abs((actual - predicted) / actual)) * 100\n",
    "    \n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'MAE': round(mae, 2),\n",
    "        'RMSE': round(rmse, 2),\n",
    "        'MAPE': round(mape, 2)\n",
    "    }\n",
    "\n",
    "print(\"Evaluation function defined\")\n",
    "print(\"Metrics: MAE (Mean Absolute Error), RMSE (Root Mean Squared Error), MAPE (Mean Absolute Percentage Error)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Prepare Train/Test Split\n",
    "\n",
    "Create time-based split and select pilot zone for model development."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1 Create Time-Based Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN/TEST SPLIT\n",
      "========================================\n",
      "Train: 2022-01-01 00:00:00 to 2024-06-30 00:00:00 (91,200 rows)\n",
      "Test:  2024-07-01 00:00:00 to 2024-12-31 00:00:00 (18,400 rows)\n",
      "\n",
      "Train months: 30\n",
      "Test months: 6\n"
     ]
    }
   ],
   "source": [
    "# What: Split data by time - train on historical, test on recent\n",
    "# Why: Time series must respect temporal order (no data leakage)\n",
    "\n",
    "TRAIN_END = '2024-06-30'\n",
    "TEST_START = '2024-07-01'\n",
    "\n",
    "train = zone_daily[zone_daily['date'] <= TRAIN_END].copy()\n",
    "test = zone_daily[zone_daily['date'] >= TEST_START].copy()\n",
    "\n",
    "print(\"TRAIN/TEST SPLIT\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Train: {train['date'].min()} to {train['date'].max()} ({len(train):,} rows)\")\n",
    "print(f\"Test:  {test['date'].min()} to {test['date'].max()} ({len(test):,} rows)\")\n",
    "print(f\"\\nTrain months: {train['date'].dt.to_period('M').nunique()}\")\n",
    "print(f\"Test months: {test['date'].dt.to_period('M').nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2 Select Pilot Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zone_daily columns: ['date', 'zone_id', 'daily_trips', 'daily_total_minutes', 'daily_avg_minutes', 'total_trip_miles', 'avg_trip_miles', 'year', 'month', 'day_of_week', 'day_name', 'is_weekend', 'month_name', 'is_outlier', 'day', 'day_of_year', 'week_of_year', 'is_month_start', 'is_month_end', 'season', 'days_since_start', 'lag_1', 'lag_7', 'lag_30', 'rolling_mean_7', 'rolling_mean_30', 'rolling_std_7', 'is_holiday']\n",
      "zone_daily zone_id dtype: object\n",
      "zone_daily zone_id sample: 0    100\n",
      "1    100\n",
      "2    100\n",
      "3    100\n",
      "4    100\n",
      "Name: zone_id, dtype: object\n",
      "Zone 138 exists? False\n",
      "zone_daily date dtype: datetime64[us]\n",
      "zone_daily date sample: 0   2022-01-01\n",
      "1   2022-01-02\n",
      "2   2022-01-03\n",
      "3   2022-01-04\n",
      "4   2022-01-05\n",
      "Name: date, dtype: datetime64[us]\n"
     ]
    }
   ],
   "source": [
    "# Check what's in the data\n",
    "print(\"zone_daily columns:\", zone_daily.columns.tolist())\n",
    "print(\"zone_daily zone_id dtype:\", zone_daily['zone_id'].dtype)\n",
    "print(\"zone_daily zone_id sample:\", zone_daily['zone_id'].head())\n",
    "print(\"Zone 138 exists?\", 138 in zone_daily['zone_id'].values)\n",
    "print(\"zone_daily date dtype:\", zone_daily['date'].dtype)\n",
    "print(\"zone_daily date sample:\", zone_daily['date'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PILOT ZONE: 138\n",
      "========================================\n",
      "Train records: 0\n",
      "Test records: 0\n",
      "Avg daily demand: nan trips\n"
     ]
    }
   ],
   "source": [
    "# What: Select top zone by volume for model development\n",
    "# Why: Develop and tune on one zone before scaling to all 100\n",
    "\n",
    "pilot_zone_id = int(selected_zones.iloc[0]['zone_id'])\n",
    "\n",
    "pilot_train = train[train['zone_id'] == pilot_zone_id].copy()\n",
    "pilot_test = test[test['zone_id'] == pilot_zone_id].copy()\n",
    "\n",
    "print(f\"PILOT ZONE: {pilot_zone_id}\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Train records: {len(pilot_train)}\")\n",
    "print(f\"Test records: {len(pilot_test)}\")\n",
    "print(f\"Avg daily demand: {pilot_train['daily_trips'].mean():,.0f} trips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PILOT ZONE: 138\n",
      "========================================\n",
      "Train records: 0\n",
      "Test records: 0\n",
      "Avg daily demand: nan trips\n"
     ]
    }
   ],
   "source": [
    "# What: Select top zone by volume for model development\n",
    "# Why: Develop and tune on one zone before scaling to all 100\n",
    "\n",
    "pilot_zone_id = int(selected_zones.iloc[0]['zone_id'])\n",
    "\n",
    "pilot_train = train[train['zone_id'] == pilot_zone_id].copy()\n",
    "pilot_test = test[test['zone_id'] == pilot_zone_id].copy()\n",
    "\n",
    "print(f\"PILOT ZONE: {pilot_zone_id}\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Train records: {len(pilot_train)}\")\n",
    "print(f\"Test records: {len(pilot_test)}\")\n",
    "print(f\"Avg daily demand: {pilot_train['daily_trips'].mean():,.0f} trips\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Build Baseline Model\n",
    "\n",
    "Implement seasonal naive baseline (7-day lag) to set performance benchmark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1 Implement Seasonal Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What: Predict using value from 7 days ago (same day of week)\n",
    "# Why: Simple benchmark that captures weekly seasonality\n",
    "\n",
    "# Create lag-7 forecast for test period\n",
    "pilot_test['baseline_pred'] = pilot_test['daily_trips'].shift(7)\n",
    "\n",
    "# For first 7 days of test, use last 7 days of train\n",
    "last_week_train = pilot_train.tail(7)['daily_trips'].values\n",
    "pilot_test.iloc[:7, pilot_test.columns.get_loc('baseline_pred')] = last_week_train\n",
    "\n",
    "print(\"Baseline model: Seasonal Naive (7-day lag)\")\n",
    "print(f\"Logic: forecast[t] = actual[t-7]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2 Evaluate Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What: Calculate baseline metrics\n",
    "# Why: This sets the bar - other models must beat this\n",
    "\n",
    "baseline_results = evaluate_forecast(\n",
    "    pilot_test['daily_trips'], \n",
    "    pilot_test['baseline_pred'],\n",
    "    model_name=\"Baseline (Seasonal Naive)\"\n",
    ")\n",
    "\n",
    "print(\"BASELINE PERFORMANCE\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"MAE:  {baseline_results['MAE']:,.0f} trips/day\")\n",
    "print(f\"RMSE: {baseline_results['RMSE']:,.0f} trips/day\")\n",
    "print(f\"MAPE: {baseline_results['MAPE']:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3 Visualize Baseline Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What: Plot baseline forecast vs actual demand\n",
    "# Why: Visual check of baseline performance\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 4))\n",
    "\n",
    "ax.plot(pilot_test['date'], pilot_test['daily_trips'], \n",
    "        label='Actual', color='steelblue', linewidth=1.5)\n",
    "ax.plot(pilot_test['date'], pilot_test['baseline_pred'], \n",
    "        label='Baseline (7-day lag)', color='coral', linewidth=1.5, linestyle='--')\n",
    "\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Daily Trips')\n",
    "ax.set_title(f'Baseline Forecast vs Actual - Zone {pilot_zone_id}')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:** [Add after running - how well does the simple lag work?]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Build Prophet Model\n",
    "\n",
    "Train Prophet to capture trend, weekly/yearly seasonality, and holidays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1 Prepare Data for Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What: Format data for Prophet (requires 'ds' and 'y' columns)\n",
    "# Why: Prophet has specific input format requirements\n",
    "\n",
    "prophet_train = pilot_train[['date', 'daily_trips']].copy()\n",
    "prophet_train.columns = ['ds', 'y']\n",
    "\n",
    "prophet_test = pilot_test[['date', 'daily_trips']].copy()\n",
    "prophet_test.columns = ['ds', 'y']\n",
    "\n",
    "print(f\"Prophet train shape: {prophet_train.shape}\")\n",
    "print(f\"Prophet test shape: {prophet_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2 Configure and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What: Initialize Prophet with weekly and yearly seasonality\n",
    "# Why: EDA showed both weekly (17% weekend lift) and yearly (13.7% range) patterns\n",
    "\n",
    "model_prophet = Prophet(\n",
    "    yearly_seasonality=True,\n",
    "    weekly_seasonality=True,\n",
    "    daily_seasonality=False,  # Data is already daily aggregated\n",
    "    seasonality_mode='multiplicative',  # Better for % changes\n",
    "    changepoint_prior_scale=0.05  # Controls trend flexibility\n",
    ")\n",
    "\n",
    "# Add US holidays (NYC market)\n",
    "model_prophet.add_country_holidays(country_name='US')\n",
    "\n",
    "# Train model\n",
    "model_prophet.fit(prophet_train)\n",
    "\n",
    "print(\"Prophet model trained\")\n",
    "print(f\"Changepoints detected: {len(model_prophet.changepoints)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.3 Generate Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What: Generate predictions for test period\n",
    "# Why: Need forecasts to compare against actual values\n",
    "\n",
    "future = prophet_test[['ds']].copy()\n",
    "prophet_forecast = model_prophet.predict(future)\n",
    "\n",
    "# Store predictions\n",
    "pilot_test['prophet_pred'] = prophet_forecast['yhat'].values\n",
    "\n",
    "print(f\"Prophet forecast generated: {len(prophet_forecast)} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.4 Evaluate Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What: Calculate Prophet metrics and compare to baseline\n",
    "# Why: Determine if Prophet adds value over simple baseline\n",
    "\n",
    "prophet_results = evaluate_forecast(\n",
    "    pilot_test['daily_trips'], \n",
    "    pilot_test['prophet_pred'],\n",
    "    model_name=\"Prophet\"\n",
    ")\n",
    "\n",
    "# Calculate improvement over baseline\n",
    "improvement = (baseline_results['MAE'] - prophet_results['MAE']) / baseline_results['MAE'] * 100\n",
    "\n",
    "print(\"PROPHET PERFORMANCE\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"MAE:  {prophet_results['MAE']:,.0f} trips/day\")\n",
    "print(f\"RMSE: {prophet_results['RMSE']:,.0f} trips/day\")\n",
    "print(f\"MAPE: {prophet_results['MAPE']:.1f}%\")\n",
    "print(f\"\\nImprovement over baseline: {improvement:+.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.5 Visualize Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What: Plot Prophet's decomposition (trend, weekly, yearly)\n",
    "# Why: Understand what patterns Prophet learned\n",
    "\n",
    "fig = model_prophet.plot_components(prophet_forecast)\n",
    "plt.suptitle(f'Prophet Components - Zone {pilot_zone_id}', fontsize=12, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:** [Add after running - what patterns did Prophet capture?]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Build XGBoost Model\n",
    "\n",
    "Train XGBoost using engineered time features and lag variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.1 Create Lag Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What: Create lag features for XGBoost\n",
    "# Why: XGBoost needs explicit features - doesn't learn time patterns automatically\n",
    "\n",
    "def create_lag_features(df, target_col='daily_trips', lags=[1, 7, 14, 28]):\n",
    "    \"\"\"Create lag features for time series modeling.\"\"\"\n",
    "    df = df.copy()\n",
    "    for lag in lags:\n",
    "        df[f'lag_{lag}'] = df.groupby('zone_id')[target_col].shift(lag)\n",
    "    \n",
    "    # Rolling features\n",
    "    df['rolling_mean_7'] = df.groupby('zone_id')[target_col].transform(\n",
    "        lambda x: x.shift(1).rolling(7, min_periods=1).mean()\n",
    "    )\n",
    "    df['rolling_mean_28'] = df.groupby('zone_id')[target_col].transform(\n",
    "        lambda x: x.shift(1).rolling(28, min_periods=1).mean()\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# Apply to full dataset then re-split\n",
    "zone_daily_features = create_lag_features(zone_daily)\n",
    "\n",
    "# Re-split with new features\n",
    "train_xgb = zone_daily_features[zone_daily_features['date'] <= TRAIN_END].copy()\n",
    "test_xgb = zone_daily_features[zone_daily_features['date'] >= TEST_START].copy()\n",
    "\n",
    "# Filter to pilot zone\n",
    "pilot_train_xgb = train_xgb[train_xgb['zone_id'] == pilot_zone_id].copy()\n",
    "pilot_test_xgb = test_xgb[test_xgb['zone_id'] == pilot_zone_id].copy()\n",
    "\n",
    "print(f\"Lag features created: lag_1, lag_7, lag_14, lag_28, rolling_mean_7, rolling_mean_28\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.2 Prepare Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What: Select features for XGBoost model\n",
    "# Why: Define which columns are predictors vs target\n",
    "\n",
    "feature_cols = [\n",
    "    # Time features (from EDA)\n",
    "    'month', 'day_of_week', 'is_weekend', 'is_holiday',\n",
    "    # Lag features\n",
    "    'lag_1', 'lag_7', 'lag_14', 'lag_28',\n",
    "    # Rolling features\n",
    "    'rolling_mean_7', 'rolling_mean_28'\n",
    "]\n",
    "\n",
    "target_col = 'daily_trips'\n",
    "\n",
    "# Remove rows with NaN from lag creation\n",
    "pilot_train_xgb = pilot_train_xgb.dropna(subset=feature_cols)\n",
    "pilot_test_xgb = pilot_test_xgb.dropna(subset=feature_cols)\n",
    "\n",
    "X_train = pilot_train_xgb[feature_cols]\n",
    "y_train = pilot_train_xgb[target_col]\n",
    "\n",
    "X_test = pilot_test_xgb[feature_cols]\n",
    "y_test = pilot_test_xgb[target_col]\n",
    "\n",
    "print(f\"Features: {len(feature_cols)}\")\n",
    "print(f\"Train samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.3 Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What: Train XGBoost regressor\n",
    "# Why: Tree-based model that handles non-linear relationships\n",
    "\n",
    "model_xgb = XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Generate predictions\n",
    "xgb_pred = model_xgb.predict(X_test)\n",
    "\n",
    "print(\"XGBoost model trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.4 Evaluate XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What: Calculate XGBoost metrics and compare to baseline\n",
    "# Why: Determine if XGBoost adds value\n",
    "\n",
    "xgb_results = evaluate_forecast(\n",
    "    y_test, \n",
    "    xgb_pred,\n",
    "    model_name=\"XGBoost\"\n",
    ")\n",
    "\n",
    "# Calculate improvement over baseline\n",
    "improvement_xgb = (baseline_results['MAE'] - xgb_results['MAE']) / baseline_results['MAE'] * 100\n",
    "\n",
    "print(\"XGBOOST PERFORMANCE\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"MAE:  {xgb_results['MAE']:,.0f} trips/day\")\n",
    "print(f\"RMSE: {xgb_results['RMSE']:,.0f} trips/day\")\n",
    "print(f\"MAPE: {xgb_results['MAPE']:.1f}%\")\n",
    "print(f\"\\nImprovement over baseline: {improvement_xgb:+.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.5 Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What: Display feature importance from XGBoost\n",
    "# Why: Understand which features drive predictions\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': model_xgb.feature_importances_\n",
    "}).sort_values('importance', ascending=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.barh(importance_df['feature'], importance_df['importance'], color='steelblue')\n",
    "ax.set_xlabel('Feature Importance')\n",
    "ax.set_title(f'XGBoost Feature Importance - Zone {pilot_zone_id}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:** [Add after running - which features matter most?]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Compare Models (Single Zone)\n",
    "\n",
    "Compare all models and select best approach for scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.1 Metrics Comparison Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What: Compare all model metrics in one table\n",
    "# Why: Easy side-by-side comparison for model selection\n",
    "\n",
    "results_df = pd.DataFrame([baseline_results, prophet_results, xgb_results])\n",
    "results_df['vs_Baseline'] = ((results_df['MAE'] - baseline_results['MAE']) / baseline_results['MAE'] * 100).round(1)\n",
    "results_df['vs_Baseline'] = results_df['vs_Baseline'].apply(lambda x: f\"{x:+.1f}%\")\n",
    "\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.2 Visualize Forecasts vs Actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What: Plot all forecasts against actual values\n",
    "# Why: Visual comparison of model performance\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "\n",
    "# Actual\n",
    "ax.plot(pilot_test['date'], pilot_test['daily_trips'], \n",
    "        label='Actual', color='black', linewidth=2)\n",
    "\n",
    "# Baseline\n",
    "ax.plot(pilot_test['date'], pilot_test['baseline_pred'], \n",
    "        label='Baseline', color='gray', linewidth=1, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Prophet\n",
    "ax.plot(pilot_test['date'], pilot_test['prophet_pred'], \n",
    "        label='Prophet', color='coral', linewidth=1.5)\n",
    "\n",
    "# XGBoost\n",
    "ax.plot(pilot_test_xgb['date'], xgb_pred, \n",
    "        label='XGBoost', color='steelblue', linewidth=1.5)\n",
    "\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Daily Trips')\n",
    "ax.set_title(f'Model Comparison - Zone {pilot_zone_id}')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.3 Select Best Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What: Determine best model for scaling\n",
    "# Why: Scale only the best performing approach to all zones\n",
    "\n",
    "best_model = results_df.loc[results_df['MAE'].idxmin(), 'Model']\n",
    "best_mae = results_df['MAE'].min()\n",
    "\n",
    "print(\"BEST MODEL SELECTION\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Best model: {best_model}\")\n",
    "print(f\"Best MAE: {best_mae:,.0f} trips/day\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:** [Add after running - which model wins and why?]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Scale to All Zones\n",
    "\n",
    "Apply best model(s) to all 100 zones and aggregate results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.1 Build Forecasting Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What: Create function to train and forecast for any zone\n",
    "# Why: Reusable pipeline for scaling to 100 zones\n",
    "\n",
    "def forecast_zone_prophet(zone_id, train_df, test_df):\n",
    "    \"\"\"Train Prophet and generate forecasts for a single zone.\"\"\"\n",
    "    # Filter to zone\n",
    "    zone_train = train_df[train_df['zone_id'] == zone_id][['date', 'daily_trips']].copy()\n",
    "    zone_test = test_df[test_df['zone_id'] == zone_id][['date', 'daily_trips']].copy()\n",
    "    \n",
    "    # Format for Prophet\n",
    "    zone_train.columns = ['ds', 'y']\n",
    "    zone_test.columns = ['ds', 'y']\n",
    "    \n",
    "    # Train\n",
    "    model = Prophet(\n",
    "        yearly_seasonality=True,\n",
    "        weekly_seasonality=True,\n",
    "        daily_seasonality=False,\n",
    "        seasonality_mode='multiplicative'\n",
    "    )\n",
    "    model.add_country_holidays(country_name='US')\n",
    "    model.fit(zone_train)\n",
    "    \n",
    "    # Forecast\n",
    "    forecast = model.predict(zone_test[['ds']])\n",
    "    \n",
    "    # Evaluate\n",
    "    mae = mean_absolute_error(zone_test['y'], forecast['yhat'])\n",
    "    \n",
    "    return {\n",
    "        'zone_id': zone_id,\n",
    "        'mae': mae,\n",
    "        'predictions': forecast['yhat'].values\n",
    "    }\n",
    "\n",
    "print(\"Forecasting pipeline defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.2 Run on All Zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What: Run forecasting pipeline on all 100 zones\n",
    "# Why: Generate forecasts for entire dataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "zone_ids = zone_daily['zone_id'].unique().tolist()\n",
    "all_results = []\n",
    "\n",
    "print(f\"Forecasting {len(zone_ids)} zones...\")\n",
    "\n",
    "for zone_id in tqdm(zone_ids):\n",
    "    try:\n",
    "        result = forecast_zone_prophet(zone_id, train, test)\n",
    "        all_results.append(result)\n",
    "    except Exception as e:\n",
    "        print(f\"Zone {zone_id} failed: {e}\")\n",
    "\n",
    "print(f\"\\nCompleted: {len(all_results)} zones\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.3 Aggregate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What: Summarize performance across all zones\n",
    "# Why: Understand overall model effectiveness\n",
    "\n",
    "zone_results_df = pd.DataFrame([{'zone_id': r['zone_id'], 'MAE': r['mae']} for r in all_results])\n",
    "\n",
    "print(\"ALL-ZONE PERFORMANCE SUMMARY\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Zones forecasted: {len(zone_results_df)}\")\n",
    "print(f\"\\nMAE Statistics:\")\n",
    "print(f\"  Mean:   {zone_results_df['MAE'].mean():,.0f} trips/day\")\n",
    "print(f\"  Median: {zone_results_df['MAE'].median():,.0f} trips/day\")\n",
    "print(f\"  Min:    {zone_results_df['MAE'].min():,.0f} trips/day\")\n",
    "print(f\"  Max:    {zone_results_df['MAE'].max():,.0f} trips/day\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Evaluate Overall Performance\n",
    "\n",
    "Analyze model performance across zones to identify patterns and problem areas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8.1 Performance by Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What: Visualize MAE distribution across zones\n",
    "# Why: Identify if performance varies by zone\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "# Histogram\n",
    "ax1.hist(zone_results_df['MAE'], bins=20, color='steelblue', edgecolor='white')\n",
    "ax1.axvline(zone_results_df['MAE'].median(), color='coral', linestyle='--', label='Median')\n",
    "ax1.set_xlabel('MAE (trips/day)')\n",
    "ax1.set_ylabel('Number of Zones')\n",
    "ax1.set_title('MAE Distribution Across Zones')\n",
    "ax1.legend()\n",
    "\n",
    "# Sorted bar\n",
    "sorted_results = zone_results_df.sort_values('MAE', ascending=False)\n",
    "ax2.bar(range(len(sorted_results)), sorted_results['MAE'], color='steelblue')\n",
    "ax2.set_xlabel('Zone (sorted by MAE)')\n",
    "ax2.set_ylabel('MAE (trips/day)')\n",
    "ax2.set_title('MAE by Zone (Worst to Best)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8.2 Identify Problem Zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What: Find zones with highest forecast error\n",
    "# Why: Identify zones that may need different approach\n",
    "\n",
    "print(\"TOP 10 WORST PERFORMING ZONES\")\n",
    "print(\"=\" * 40)\n",
    "worst_zones = zone_results_df.nlargest(10, 'MAE')\n",
    "display(worst_zones)\n",
    "\n",
    "print(\"\\nTOP 10 BEST PERFORMING ZONES\")\n",
    "print(\"=\" * 40)\n",
    "best_zones = zone_results_df.nsmallest(10, 'MAE')\n",
    "display(best_zones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:** [Add after running - what patterns emerge? Do high-volume zones perform differently?]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Save Results\n",
    "\n",
    "Save forecasts and model artifacts for future use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9.1 Save Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What: Save zone-level results and forecasts\n",
    "# Why: Preserve outputs for reporting and analysis\n",
    "\n",
    "OUTPUT_DIR = Path(\"../data/model_outputs\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Save zone performance summary\n",
    "zone_results_df.to_csv(OUTPUT_DIR / \"zone_forecast_performance.csv\", index=False)\n",
    "print(f\"Saved: {OUTPUT_DIR / 'zone_forecast_performance.csv'}\")\n",
    "\n",
    "# Save comparison results\n",
    "results_df.to_csv(OUTPUT_DIR / \"model_comparison.csv\", index=False)\n",
    "print(f\"Saved: {OUTPUT_DIR / 'model_comparison.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "[Add after running - summarize results, best model, key findings]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future Work\n",
    "\n",
    "- Hyperparameter tuning for Prophet and XGBoost\n",
    "- Ensemble methods (blend Prophet + XGBoost)\n",
    "- Zone-specific models for problem zones\n",
    "- Cross-validation for more robust evaluation\n",
    "- Feature engineering improvements"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
