{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYC Rideshare Forecasting Pipeline - Part 2: Data Validation\n",
    "\n",
    "**Author:** K Flowers  \n",
    "**GitHub:** [github.com/KRFlowers](https://github.com/KRFlowers)  \n",
    "**Date:** December 2025\n",
    "\n",
    "This notebook validates the 684M NYC FHV (Uber/Lyft) trip records acquired during the download phase. It flags invalid records based on duration, distance, and fare thresholds. Finally, it outputs a clean dataset for EDA and modeling.\n",
    "\n",
    "\n",
    "**Pipeline Position:** Notebook 2 of 4 — Data Validation\n",
    "\n",
    "- 00_data_download.ipynb\n",
    "- 01_data_validation.ipynb ← **this notebook**\n",
    "- 02_exploratory_analysis.ipynb\n",
    "- 03_demand_forecasting.ipynb\n",
    "\n",
    "**Objective:** Validate raw trip records against thresholds for duration, distance, and fare. Create a clean dataset containing only valid data. \n",
    "\n",
    "**Technical Approach:**\n",
    "- Use DuckDB for memory-efficient processing of 18GB dataset\n",
    "- Set validation thresholds for duration, distance, and fare fields\n",
    "- Flag invalid records and save to a new dataset to preserve the original full dataset\n",
    "\n",
    "**Inputs:**\n",
    "- `data/raw/combined_fhvhv_tripdata.parquet` — Combined trip data (18GB)\n",
    "\n",
    "**Outputs:**\n",
    "- `data/validated/fhvhv_valid_data_for_eda.parquet` - Clean dataset for EDA (683M records)\n",
    "- `data/validated/fhvhv_all_data_flagged.parquet` - All records with validation flags (684M)\n",
    "- `data/quality_reports/validation_report.csv` - Validation metrics by rule\n",
    "\n",
    "\n",
    "**Runtime:** ~30 minutes (flagging ~20 min, validation counts ~10 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configure Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# Core data libraries\n",
    "import pandas as pd\n",
    "import duckdb\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Set Display and Plot Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Set Paths and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config loaded: combined_fhvhv_tripdata.parquet\n"
     ]
    }
   ],
   "source": [
    "# Project Constants\n",
    "PROJECT_YEARS = [2022, 2023, 2024]\n",
    "TLC_DATASET = 'fhvhv'\n",
    "\n",
    "# Paths\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "RAW_DIR = PROJECT_ROOT / \"data\" / \"raw\"\n",
    "VALIDATED_DIR = PROJECT_ROOT / \"data\" / \"validated\"\n",
    "REPORTS_DIR = PROJECT_ROOT / \"data\" / \"quality_reports\"\n",
    "\n",
    "# Input/Output Files\n",
    "INPUT_FILE = RAW_DIR / f\"combined_{TLC_DATASET}_tripdata.parquet\"\n",
    "FLAGGED_FILE = VALIDATED_DIR / f\"{TLC_DATASET}_all_data_flagged.parquet\"\n",
    "EDA_FILE = VALIDATED_DIR / f\"{TLC_DATASET}_valid_data_for_eda.parquet\"\n",
    "\n",
    "# Create Directories\n",
    "VALIDATED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "REPORTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Config loaded: {INPUT_FILE.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Create Database Connection\n",
    "Initialize DuckDB connection and configure performance settings. Database connection is required to validate the combined trip data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DuckDB connection established\n"
     ]
    }
   ],
   "source": [
    "# Initialize DuckDB connection with optimized settings\n",
    "con = duckdb.connect()\n",
    "con.execute(\"SET threads=4\")\n",
    "con.execute(\"SET preserve_insertion_order=false\")\n",
    "#con.execute(\"SET enable_progress_bar = true\")\n",
    "#con.execute(\"SET progress_bar_time = 2000\")\n",
    "print(\"DuckDB connection established\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Review Data\n",
    "Reviews the dataset structure, date range coverage, and missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Review Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 684,376,551\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>column_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hvfhs_license_num</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dispatching_base_num</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>originating_base_num</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>request_datetime</td>\n",
       "      <td>TIMESTAMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>on_scene_datetime</td>\n",
       "      <td>TIMESTAMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pickup_datetime</td>\n",
       "      <td>TIMESTAMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dropoff_datetime</td>\n",
       "      <td>TIMESTAMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PULocationID</td>\n",
       "      <td>BIGINT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DOLocationID</td>\n",
       "      <td>BIGINT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>trip_miles</td>\n",
       "      <td>DOUBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>trip_time</td>\n",
       "      <td>BIGINT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>base_passenger_fare</td>\n",
       "      <td>DOUBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tolls</td>\n",
       "      <td>DOUBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bcf</td>\n",
       "      <td>DOUBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sales_tax</td>\n",
       "      <td>DOUBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>congestion_surcharge</td>\n",
       "      <td>DOUBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>airport_fee</td>\n",
       "      <td>DOUBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tips</td>\n",
       "      <td>DOUBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>driver_pay</td>\n",
       "      <td>DOUBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>shared_request_flag</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>shared_match_flag</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>access_a_ride_flag</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>wav_request_flag</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>wav_match_flag</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             column_name column_type\n",
       "0      hvfhs_license_num     VARCHAR\n",
       "1   dispatching_base_num     VARCHAR\n",
       "2   originating_base_num     VARCHAR\n",
       "3       request_datetime   TIMESTAMP\n",
       "4      on_scene_datetime   TIMESTAMP\n",
       "5        pickup_datetime   TIMESTAMP\n",
       "6       dropoff_datetime   TIMESTAMP\n",
       "7           PULocationID      BIGINT\n",
       "8           DOLocationID      BIGINT\n",
       "9             trip_miles      DOUBLE\n",
       "10             trip_time      BIGINT\n",
       "11   base_passenger_fare      DOUBLE\n",
       "12                 tolls      DOUBLE\n",
       "13                   bcf      DOUBLE\n",
       "14             sales_tax      DOUBLE\n",
       "15  congestion_surcharge      DOUBLE\n",
       "16           airport_fee      DOUBLE\n",
       "17                  tips      DOUBLE\n",
       "18            driver_pay      DOUBLE\n",
       "19   shared_request_flag     VARCHAR\n",
       "20     shared_match_flag     VARCHAR\n",
       "21    access_a_ride_flag     VARCHAR\n",
       "22      wav_request_flag     VARCHAR\n",
       "23        wav_match_flag     VARCHAR"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display total record count\n",
    "total_records = con.execute(f\"SELECT COUNT(*) FROM '{INPUT_FILE}'\").fetchone()[0]\n",
    "print(f\"Total records: {total_records:,}\\n\")\n",
    "\n",
    "# Review column names and data types\n",
    "con.execute(f\"DESCRIBE SELECT * FROM '{INPUT_FILE}'\").df()[['column_name', 'column_type']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Check Date Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date range: 2022-01-01 00:00:00 to 2024-12-31 23:59:59\n"
     ]
    }
   ],
   "source": [
    "# Check date range of pickup_datetime to verify coverage period\n",
    "date_range = con.execute(f\"\"\"\n",
    "    SELECT \n",
    "        MIN(pickup_datetime) as earliest,\n",
    "        MAX(pickup_datetime) as latest\n",
    "    FROM '{INPUT_FILE}'\n",
    "\"\"\").df()\n",
    "\n",
    "print(f\"Date range: {date_range['earliest'].iloc[0]} to {date_range['latest'].iloc[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Check Missing Values\n",
    "Identify null values by column. High-null columns will be excluded during aggregation in EDA, not removed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column                    Null Count   Null Percentage\n",
      "--------------------------------------------------\n",
      "hvfhs_license_num         0                       0.00%\n",
      "dispatching_base_num      0                       0.00%\n",
      "originating_base_num      183954837              26.88%\n",
      "request_datetime          0                       0.00%\n",
      "on_scene_datetime         183891654              26.87%\n",
      "pickup_datetime           0                       0.00%\n",
      "dropoff_datetime          0                       0.00%\n",
      "PULocationID              0                       0.00%\n",
      "DOLocationID              0                       0.00%\n",
      "trip_miles                0                       0.00%\n",
      "trip_time                 0                       0.00%\n",
      "base_passenger_fare       0                       0.00%\n",
      "tolls                     0                       0.00%\n",
      "bcf                       0                       0.00%\n",
      "sales_tax                 0                       0.00%\n",
      "congestion_surcharge      0                       0.00%\n",
      "airport_fee               0                       0.00%\n",
      "tips                      0                       0.00%\n",
      "driver_pay                0                       0.00%\n",
      "shared_request_flag       0                       0.00%\n",
      "shared_match_flag         0                       0.00%\n",
      "access_a_ride_flag        0                       0.00%\n",
      "wav_request_flag          0                       0.00%\n",
      "wav_match_flag            0                       0.00%\n"
     ]
    }
   ],
   "source": [
    "# Get list of column names\n",
    "columns = con.execute(f\"DESCRIBE SELECT * FROM '{INPUT_FILE}'\").df()['column_name'].tolist()\n",
    "\n",
    "# Build SQL to count NULLs per column using CASE WHEN - single scan counts nulls for all columns once\n",
    "null_count_sql = f\"\"\"\n",
    "    SELECT \n",
    "        {', '.join([f\"SUM(CASE WHEN {col} IS NULL THEN 1 ELSE 0 END) AS {col}_null_count\" for col in columns])}\n",
    "    FROM '{INPUT_FILE}'\n",
    "\"\"\"\n",
    "\n",
    "# Execute query and get results as tuple\n",
    "null_counts = con.execute(null_count_sql).fetchone()\n",
    "\n",
    "# Calculate null percentages\n",
    "null_pct = [(count / total_records) * 100 for count in null_counts]\n",
    "\n",
    "# Display results \n",
    "print(f\"{'Column':<25} {'Null Count':<12} {'Null Percentage'}\")\n",
    "print(\"-\" * 50)\n",
    "for col, count, pct in zip(columns, null_counts, null_pct):\n",
    "    print(f\"{col:<25} {count:<12} {pct:>15.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Core fields that will be used for analysis have zero nulls:\n",
    "- `pickup_datetime`\n",
    "- `PULocationID`\n",
    "- `trip_time`\n",
    "- `trip_miles`\n",
    "- `base_passenger_fare`\n",
    "\n",
    "The two high-null columns (`originating_base_num`, `on_scene_datetime`) are not used in this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Validate Data\n",
    "Flags all records based on duration, distance, and fare thresholds. Creates two output datasets: one with all 684M records and quality flags, and one with only valid records for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Set Validation Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set validation thresholds for key fields that impact analysis\n",
    "\n",
    "DURATION_MIN = 60          # 1 min - filters GPS errors, keeps short trips\n",
    "DURATION_MAX = 43200       # 12 hrs - covers NYC to Philadelphia\n",
    "DURATION_EXTREME = 604800  # 7 days - obvious corruption\n",
    "DISTANCE_MIN = 0.1         # Filters GPS noise\n",
    "DISTANCE_MAX = 200         # NYC-Philadelphia service area\n",
    "FARE_MIN = 0               # No negative fares ($0 allowed for promos)\n",
    "FARE_MAX = 500             # 99.9th percentile ~$150, allows surge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Flag Records Against Thresholds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating flagged dataset...\n",
      "This will take approximately 10 minutes for 684M records\n",
      "\n",
      "Flagged dataset created: 684,376,551 records\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating flagged dataset...\")\n",
    "print(\"This will take approximately 10 minutes for 684M records\\n\")\n",
    "\n",
    "# Validate key fields, create flags and save dataset with flags\n",
    "con.execute(f\"\"\"\n",
    "    COPY (\n",
    "        SELECT \n",
    "            *,\n",
    "            \n",
    "            -- DURATION FLAGS - Checking null, zero/negative, min, max, and extreme\n",
    "            (trip_time IS NULL) AS flag_duration_null,\n",
    "            (trip_time <= 0) AS flag_duration_zero_negative,\n",
    "            (trip_time < {DURATION_MIN}) AS flag_duration_too_short,\n",
    "            (trip_time > {DURATION_MAX}) AS flag_duration_exceeds_max,\n",
    "            (trip_time > {DURATION_EXTREME}) AS flag_duration_extreme,\n",
    "            \n",
    "            -- DISTANCE FLAGS - Checking null, negative, min, and max \n",
    "            (trip_miles IS NULL) AS flag_distance_null,\n",
    "            (trip_miles < 0) AS flag_distance_negative,\n",
    "            (trip_miles < {DISTANCE_MIN}) AS flag_distance_too_short,\n",
    "            (trip_miles > {DISTANCE_MAX}) AS flag_distance_exceeds_max,\n",
    "            \n",
    "            -- FARE FLAGS - Checking null, negative, zero, and extreme high \n",
    "            (base_passenger_fare IS NULL) AS flag_fare_null,\n",
    "            (base_passenger_fare < {FARE_MIN}) AS flag_fare_negative,\n",
    "            (base_passenger_fare = 0) AS flag_fare_zero,\n",
    "            (base_passenger_fare > {FARE_MAX}) AS flag_fare_extreme_high,\n",
    "            \n",
    "            -- APPLYY MASTER VALIDITY FLAG - Record is valid if all checks pass (zero fare is allowed)\n",
    "            (\n",
    "                trip_time IS NOT NULL AND\n",
    "                trip_time >= {DURATION_MIN} AND \n",
    "                trip_time <= {DURATION_MAX} AND\n",
    "                trip_miles IS NOT NULL AND\n",
    "                trip_miles >= {DISTANCE_MIN} AND\n",
    "                trip_miles <= {DISTANCE_MAX} AND\n",
    "                base_passenger_fare IS NOT NULL AND\n",
    "                base_passenger_fare >= {FARE_MIN} AND\n",
    "                base_passenger_fare <= {FARE_MAX}\n",
    "            ) AS is_valid\n",
    "            \n",
    "        FROM '{INPUT_FILE}'\n",
    "    ) TO '{FLAGGED_FILE}' (FORMAT PARQUET)\n",
    "\"\"\")\n",
    "\n",
    "# Verify the flagged dataset was created successfully\n",
    "flagged_count = con.execute(f\"SELECT COUNT(*) FROM '{FLAGGED_FILE}'\").fetchone()[0]\n",
    "print(f\"Flagged dataset created: {flagged_count:,} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_time</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>base_passenger_fare</th>\n",
       "      <th>flag_duration_too_short</th>\n",
       "      <th>flag_distance_too_short</th>\n",
       "      <th>flag_fare_negative</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>687</td>\n",
       "      <td>6.0800</td>\n",
       "      <td>-8.3500</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>184</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>10.7900</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>368</td>\n",
       "      <td>1.5600</td>\n",
       "      <td>-4.7300</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>443</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>-3.8700</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>727</td>\n",
       "      <td>4.1300</td>\n",
       "      <td>-1.6100</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>473</td>\n",
       "      <td>0.4600</td>\n",
       "      <td>-3.6100</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>59</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>16.9900</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1126</td>\n",
       "      <td>8.2000</td>\n",
       "      <td>-1.1500</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>361</td>\n",
       "      <td>1.1100</td>\n",
       "      <td>-0.9400</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1115</td>\n",
       "      <td>1.9900</td>\n",
       "      <td>-2.7500</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2409</td>\n",
       "      <td>11.1000</td>\n",
       "      <td>-7.8200</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>504</td>\n",
       "      <td>1.4100</td>\n",
       "      <td>-5.7300</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>363</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>7.1900</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>406</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>-3.8700</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>62</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>7.9100</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2022</td>\n",
       "      <td>12.2300</td>\n",
       "      <td>-12.4400</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>216</td>\n",
       "      <td>1.1500</td>\n",
       "      <td>-0.9400</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>529</td>\n",
       "      <td>1.1300</td>\n",
       "      <td>-5.4500</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>243</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-1.1800</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>318</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>-0.9900</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    trip_time  trip_miles  base_passenger_fare  flag_duration_too_short  \\\n",
       "0         687      6.0800              -8.3500                    False   \n",
       "1         184      0.0100              10.7900                    False   \n",
       "2         368      1.5600              -4.7300                    False   \n",
       "3         443      0.5200              -3.8700                    False   \n",
       "4         727      4.1300              -1.6100                    False   \n",
       "5         473      0.4600              -3.6100                    False   \n",
       "6          59      0.2000              16.9900                     True   \n",
       "7        1126      8.2000              -1.1500                    False   \n",
       "8         361      1.1100              -0.9400                    False   \n",
       "9        1115      1.9900              -2.7500                    False   \n",
       "10       2409     11.1000              -7.8200                    False   \n",
       "11        504      1.4100              -5.7300                    False   \n",
       "12        363      0.0100               7.1900                    False   \n",
       "13        406      0.0300              -3.8700                    False   \n",
       "14         62      0.0000               7.9100                    False   \n",
       "15       2022     12.2300             -12.4400                    False   \n",
       "16        216      1.1500              -0.9400                    False   \n",
       "17        529      1.1300              -5.4500                    False   \n",
       "18        243      0.0000              -1.1800                    False   \n",
       "19        318      0.9500              -0.9900                    False   \n",
       "\n",
       "    flag_distance_too_short  flag_fare_negative  is_valid  \n",
       "0                     False                True     False  \n",
       "1                      True               False     False  \n",
       "2                     False                True     False  \n",
       "3                     False                True     False  \n",
       "4                     False                True     False  \n",
       "5                     False                True     False  \n",
       "6                     False               False     False  \n",
       "7                     False                True     False  \n",
       "8                     False                True     False  \n",
       "9                     False                True     False  \n",
       "10                    False                True     False  \n",
       "11                    False                True     False  \n",
       "12                     True               False     False  \n",
       "13                     True                True     False  \n",
       "14                     True               False     False  \n",
       "15                    False                True     False  \n",
       "16                    False                True     False  \n",
       "17                    False                True     False  \n",
       "18                     True                True     False  \n",
       "19                    False                True     False  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review a sample of flagged records to verify validation logic\n",
    "con.execute(f\"\"\"\n",
    "    SELECT \n",
    "        trip_time,\n",
    "        trip_miles,\n",
    "        base_passenger_fare,\n",
    "        flag_duration_too_short,\n",
    "        flag_distance_too_short,\n",
    "        flag_fare_negative,\n",
    "        is_valid\n",
    "    FROM '{FLAGGED_FILE}'\n",
    "    WHERE is_valid = FALSE\n",
    "    LIMIT 20\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Count Flagged Records\n",
    "Counts invalid records overall and then by zone.  Verify no zone exceeds the 1% exclusion threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation counts complete: 684,376,551 records\n"
     ]
    }
   ],
   "source": [
    "# Count all validation flags in one query\n",
    "validation_stats = con.execute(f\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as total,\n",
    "        \n",
    "        -- Duration issues\n",
    "        SUM(CAST(flag_duration_null AS INTEGER)) as dur_null,\n",
    "        SUM(CAST(flag_duration_zero_negative AS INTEGER)) as dur_zero_neg,\n",
    "        SUM(CAST(flag_duration_too_short AS INTEGER)) as dur_too_short,\n",
    "        SUM(CAST(flag_duration_exceeds_max AS INTEGER)) as dur_exceeds_max,\n",
    "        SUM(CAST(flag_duration_extreme AS INTEGER)) as dur_extreme,\n",
    "        \n",
    "        -- Distance issues\n",
    "        SUM(CAST(flag_distance_null AS INTEGER)) as dist_null,\n",
    "        SUM(CAST(flag_distance_negative AS INTEGER)) as dist_negative,\n",
    "        SUM(CAST(flag_distance_too_short AS INTEGER)) as dist_too_short,\n",
    "        SUM(CAST(flag_distance_exceeds_max AS INTEGER)) as dist_exceeds_max,\n",
    "        \n",
    "        -- Fare issues\n",
    "        SUM(CAST(flag_fare_null AS INTEGER)) as fare_null,\n",
    "        SUM(CAST(flag_fare_negative AS INTEGER)) as fare_negative,\n",
    "        SUM(CAST(flag_fare_zero AS INTEGER)) as fare_zero,\n",
    "        SUM(CAST(flag_fare_extreme_high AS INTEGER)) as fare_extreme_high,\n",
    "        \n",
    "        -- Overall validity\n",
    "        SUM(CAST(is_valid AS INTEGER)) as valid,\n",
    "        SUM(CAST(NOT is_valid AS INTEGER)) as invalid\n",
    "        \n",
    "    FROM '{FLAGGED_FILE}'\n",
    "\"\"\").fetchone()\n",
    "\n",
    "# Unpack results\n",
    "(total, \n",
    " dur_null, dur_zero_neg, dur_too_short, dur_exceeds_max, dur_extreme,\n",
    " dist_null, dist_negative, dist_too_short, dist_exceeds_max,\n",
    " fare_null, fare_negative, fare_zero, fare_extreme_high,\n",
    " valid, invalid) = validation_stats\n",
    "\n",
    "print(f\"Validation counts complete: {total:,} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count each validation flag\n",
    "flag_counts = con.execute(f\"\"\"\n",
    "    SELECT \n",
    "        SUM(CAST(flag_duration_null AS INT)) as flag_duration_null,\n",
    "        SUM(CAST(flag_duration_zero_negative AS INT)) as flag_duration_zero_negative,\n",
    "        SUM(CAST(flag_duration_too_short AS INT)) as flag_duration_too_short,\n",
    "        SUM(CAST(flag_duration_exceeds_max AS INT)) as flag_duration_exceeds_max,\n",
    "        SUM(CAST(flag_duration_extreme AS INT)) as flag_duration_extreme,\n",
    "        SUM(CAST(flag_distance_null AS INT)) as flag_distance_null,\n",
    "        SUM(CAST(flag_distance_negative AS INT)) as flag_distance_negative,\n",
    "        SUM(CAST(flag_distance_too_short AS INT)) as flag_distance_too_short,\n",
    "        SUM(CAST(flag_distance_exceeds_max AS INT)) as flag_distance_exceeds_max,\n",
    "        SUM(CAST(flag_fare_null AS INT)) as flag_fare_null,\n",
    "        SUM(CAST(flag_fare_negative AS INT)) as flag_fare_negative,\n",
    "        SUM(CAST(flag_fare_zero AS INT)) as flag_fare_zero,\n",
    "        SUM(CAST(flag_fare_extreme_high AS INT)) as flag_fare_extreme_high\n",
    "    FROM '{FLAGGED_FILE}'\n",
    "\"\"\").df().T\n",
    "\n",
    "flag_counts.columns = ['count']\n",
    "flag_counts['pct'] = (flag_counts['count'] / total * 100).apply(lambda x: f\"{x:.3f}%\")\n",
    "flag_counts['count'] = flag_counts['count'].apply(lambda x: f\"{x:,.0f}\")\n",
    "\n",
    "print(f\"Total: {total:,} | Valid: {valid:,} ({valid/total*100:.2f}%) | Invalid: {invalid:,} ({invalid/total*100:.2f}%)\\n\")\n",
    "flag_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** 99.91% of records passed validation (683.8M of 684.4M). Only 596K excluded—thresholds were strict enough to catch errors without removing legitimate edge cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 zones exceed 1% invalid rate:\n",
      "   zone_id  total  invalid  invalid_pct\n",
      "0        1     67  15.0000      22.3900\n"
     ]
    }
   ],
   "source": [
    "# Check invalid rate by zone to verify no bias by location\n",
    "zone_validity = con.execute(f\"\"\"\n",
    "    SELECT \n",
    "        PULocationID as zone_id,\n",
    "        COUNT(*) as total,\n",
    "        SUM(CASE WHEN is_valid = FALSE THEN 1 ELSE 0 END) as invalid,\n",
    "        ROUND(SUM(CASE WHEN is_valid = FALSE THEN 1 ELSE 0 END) * 100.0 / COUNT(*), 2) as invalid_pct\n",
    "    FROM '{FLAGGED_FILE}'\n",
    "    GROUP BY PULocationID\n",
    "    HAVING invalid_pct > 1.0\n",
    "    ORDER BY invalid_pct DESC\n",
    "\"\"\").df()\n",
    "\n",
    "if len(zone_validity) == 0:\n",
    "    print(\"No zones exceed 1% invalid rate\")\n",
    "else:\n",
    "    print(f\"{len(zone_validity)} zones exceed 1% invalid rate:\")\n",
    "    print(zone_validity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Zone 1 exceeds 1% invalid rate (22%) but has only 67 total trips. This zone is filtered out in EDA due to incomplete temporal coverage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Save Valid Records Dataset\n",
    "(~10 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create EDA dataset with only valid records, excluding flag columns\n",
    "con.execute(f\"\"\"\n",
    "    COPY (\n",
    "        SELECT * EXCLUDE (\n",
    "            flag_duration_null, \n",
    "            flag_duration_zero_negative, \n",
    "            flag_duration_too_short, \n",
    "            flag_duration_exceeds_max, \n",
    "            flag_duration_extreme,\n",
    "            flag_distance_null, \n",
    "            flag_distance_negative, \n",
    "            flag_distance_too_short, \n",
    "            flag_distance_exceeds_max,\n",
    "            flag_fare_null, \n",
    "            flag_fare_negative, \n",
    "            flag_fare_zero, \n",
    "            flag_fare_extreme_high,\n",
    "            is_valid\n",
    "        )\n",
    "        FROM '{FLAGGED_FILE}'\n",
    "        WHERE is_valid = true\n",
    "    ) TO '{EDA_FILE}' (FORMAT PARQUET)\n",
    "\"\"\")\n",
    "print(f\"EDA dataset saved: {EDA_FILE.name} ({valid:,} records)\\n\")\n",
    "\n",
    "# Preview saved dataset\n",
    "con.execute(f\"SELECT * FROM '{EDA_FILE}' LIMIT 3\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Save Flag Counts Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save validation flag counts to CSV\n",
    "flag_counts.to_csv(REPORTS_DIR / \"validation_report.csv\")\n",
    "print(f\"Saved: validation_report.csv\\n\")\n",
    "\n",
    "# Preview saved report\n",
    "flag_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline complete\n"
     ]
    }
   ],
   "source": [
    "# Close DuckDB connection\n",
    "con.close()\n",
    "print(\"Pipeline complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
